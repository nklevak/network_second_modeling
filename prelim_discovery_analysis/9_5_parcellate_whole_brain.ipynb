{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217e38c4-20cb-45b1-89e3-ab3eb3b968d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parcellates each map with the smorgasbord atlas (includes both cortical and subcortical) and saves the df in smor_parcel_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cf791c3-3e02-4e38-b97e-111f684e37fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "import nilearn\n",
    "import json\n",
    "import datetime\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import gc\n",
    "import psutil\n",
    "import math\n",
    "import scipy.stats as stats\n",
    "from matplotlib.patches import Patch\n",
    "from nilearn import plotting\n",
    "from nilearn.glm.first_level import FirstLevelModel\n",
    "from nilearn.glm.second_level import SecondLevelModel\n",
    "from nilearn.glm import threshold_stats_img\n",
    "from nilearn.image import concat_imgs, mean_img, index_img\n",
    "from nilearn.reporting import make_glm_report\n",
    "from nilearn import masking, image\n",
    "from nilearn import datasets\n",
    "from scipy.stats import pearsonr\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from nilearn.maskers import NiftiLabelsMasker\n",
    "from sklearn.utils import Bunch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6075e87-1582-4028-a7cc-0838b8d32f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general helper functions:\n",
    "def build_contrast_map_path(base_dir, level, subject, session, task, contrast_name):\n",
    "    \"\"\"Build the file path for a contrast map.\"\"\"\n",
    "    filename = f'{subject}_{session}_task-{task}_contrast-{contrast_name}_rtmodel-rt_centered_stat-effect-size.nii.gz'\n",
    "    \n",
    "    # NOTE: as of 7/6/25 for sub 10 in flanker the format is different: sub-s10_ses-01_run-1_task-flanker_contrast-incongruent-congruent_rtmodel-rt_centered_stat-effect-size.nii.gz\n",
    "    if (subject == 'sub-s10' and task == 'flanker'):\n",
    "        filename = f'{subject}_{session}_run-1_task-{task}_contrast-{contrast_name}_rtmodel-rt_centered_stat-effect-size.nii.gz'\n",
    "    # NOTE: as of 10/1/25 for sub 3 in all tasks the format is different: (also has run-1)\n",
    "    if (subject == 'sub-s03'):\n",
    "        filename = f'{subject}_{session}_run-1_task-{task}_contrast-{contrast_name}_rtmodel-rt_centered_stat-effect-size.nii.gz'\n",
    "        \n",
    "    return os.path.join(base_dir, level, subject, task, 'indiv_contrasts', filename)\n",
    "\n",
    "def is_valid_contrast_map(img_path):\n",
    "    \"\"\"Check if a contrast map has sufficient variance and no NaN values.\"\"\"\n",
    "    try:\n",
    "        img = nib.load(img_path)\n",
    "        data = img.get_fdata()\n",
    "        return np.std(data) > 1e-10 and not np.isnan(data).any()\n",
    "    except Exception as e:\n",
    "        print(f\"Error validating {img_path}: {e}\")\n",
    "        return False\n",
    "        \n",
    "def clean_z_map_data(z_map, task, contrast_name, encounter):\n",
    "    \"\"\"Clean z-map data by handling NaN and infinity values.\"\"\"\n",
    "    data = z_map.get_fdata()\n",
    "    if np.isnan(data).any() or np.isinf(data).any():\n",
    "        data = np.nan_to_num(data)\n",
    "        z_map = nib.Nifti1Image(data, z_map.affine, z_map.header)\n",
    "        print(f\"Warning: Fixed NaN/Inf values in {task}:{contrast_name}:encounter-{encounter+1}\")\n",
    "    return z_map\n",
    "\n",
    "def cleanup_memory():\n",
    "    \"\"\"\n",
    "    Clean up memory between batches\n",
    "    \"\"\"\n",
    "    # Force garbage collection\n",
    "    gc.collect()\n",
    "    \n",
    "    # Get memory info\n",
    "    memory = psutil.virtual_memory()\n",
    "    print(f\"Memory after cleanup: {memory.percent:.1f}% used ({memory.available/(1024**3):.1f}GB available)\")\n",
    "    \n",
    "def convert_to_regular_dict(d):\n",
    "    if isinstance(d, defaultdict):\n",
    "        return {k: convert_to_regular_dict(v) for k, v in d.items()}\n",
    "    elif isinstance(d, list):\n",
    "        return [convert_to_regular_dict(i) for i in d]\n",
    "    else:\n",
    "        return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "206a323f-80e4-4adb-87e7-14b80b95a812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['twoBack-oneBack', 'match-mismatch', 'task-baseline', 'response_time', 'incongruent-congruent', 'neg-con', 'nogo_success-go', 'nogo_success', 'DDD', 'DDS', 'DNN', 'DSD', 'main_vars', 'SDD', 'SNN', 'SSS', 'go', 'stop_failure-go', 'stop_failure', 'stop_failure-stop_success', 'stop_success-go', 'stop_success', 'stop_success-stop_failure', 'cue_switch_cost', 'task_switch_cost', 'task_switch_cue_switch-task_stay_cue_stay']\n"
     ]
    }
   ],
   "source": [
    "# all tasks and contrasts\n",
    "TASKS = [\"nBack\",\"flanker\",\"directedForgetting\",\"goNogo\", \"shapeMatching\", \"stopSignal\", \"cuedTS\", \"spatialTS\"]\n",
    "CONTRASTS = {}\n",
    "CONTRASTS[\"nBack\"] = [\"twoBack-oneBack\", \"match-mismatch\",\"task-baseline\",\"response_time\"] # the nback contrasts\n",
    "CONTRASTS[\"flanker\"] = [\"incongruent-congruent\", \"task-baseline\"]\n",
    "CONTRASTS[\"directedForgetting\"] = [\"neg-con\", \"task-baseline\",\"response_time\"]\n",
    "CONTRASTS[\"goNogo\"] = [\"nogo_success-go\", \"nogo_success\",\"task-baseline\",\"response_time\"] # go_rtModel check\n",
    "CONTRASTS[\"shapeMatching\"] = [\"DDD\", \"DDS\", \"DNN\", \"DSD\", \"main_vars\", \"SDD\", \"SNN\", \"SSS\", \"task-baseline\",\"response_time\"]\n",
    "CONTRASTS[\"stopSignal\"] = [\"go\", \"stop_failure-go\", \"stop_failure\", \"stop_failure-stop_success\", \"stop_success-go\", \"stop_success\", \"stop_success-stop_failure\", \"task-baseline\",\"response_time\"]\n",
    "CONTRASTS[\"cuedTS\"] = [\"cue_switch_cost\", \"task_switch_cost\", \"task_switch_cue_switch-task_stay_cue_stay\", \"task-baseline\",\"response_time\"]\n",
    "CONTRASTS[\"spatialTS\"] = [\"cue_switch_cost\", \"task_switch_cost\", \"task_switch_cue_switch-task_stay_cue_stay\", \"task-baseline\",\"response_time\"]\n",
    "\n",
    "# interested in looking at them all now:\n",
    "requested_task_contrasts = defaultdict(lambda: defaultdict(list))\n",
    "requested_task_contrasts['nBack'] = CONTRASTS[\"nBack\"]\n",
    "requested_task_contrasts['flanker'] = CONTRASTS[\"flanker\"]\n",
    "requested_task_contrasts['directedForgetting'] = CONTRASTS[\"directedForgetting\"]\n",
    "requested_task_contrasts['goNogo'] = CONTRASTS[\"goNogo\"]\n",
    "requested_task_contrasts['shapeMatching'] = CONTRASTS[\"shapeMatching\"]\n",
    "requested_task_contrasts['stopSignal'] = CONTRASTS[\"stopSignal\"]\n",
    "requested_task_contrasts['cuedTS'] = CONTRASTS[\"cuedTS\"]\n",
    "requested_task_contrasts['spatialTS'] = CONTRASTS[\"spatialTS\"] \n",
    "\n",
    "# compiled_req_contrasts = [\"twoBack-oneBack\", 'task-baseline', \"incongruent-congruent\", \"neg-con\", \"nogo_success-go\", \"main_vars\", \"stop_failure-go\",\"task_switch_cost\"]\n",
    "\n",
    "encounters = ['01', '02','03','04','05']\n",
    "\n",
    "# compile all requested contrasts into one list\n",
    "compiled_req_contrasts = []\n",
    "for task in TASKS:\n",
    "    for contrast in requested_task_contrasts[task]:\n",
    "        if (contrast not in compiled_req_contrasts):\n",
    "            compiled_req_contrasts.append(contrast)\n",
    "print(compiled_req_contrasts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4933e33-f816-4358-b2a3-8dcf1ab105da",
   "metadata": {},
   "source": [
    "# Load subject files per session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2156dd88-b079-4ccd-8c37-62f90cf9746e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load files per subject per session\n",
    "\n",
    "# where the first level contrast maps are stored\n",
    "BASE_DIR = '/oak/stanford/groups/russpold/data/network_grant/discovery_BIDS_20250402/derivatives/'\n",
    "LEVEL = 'output_lev1_mni'\n",
    "# subjects in the discovery sample\n",
    "SUBJECTS = ['sub-s03', 'sub-s10', 'sub-s19', 'sub-s29', 'sub-s43']\n",
    "SESSIONS = ['ses-01', 'ses-02', 'ses-03', 'ses-04', 'ses-05', 'ses-06', 'ses-07', 'ses-08', 'ses-09','ses-10']\n",
    "\n",
    "# number of encounters each subject has with a task\n",
    "max_num_encounters = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18619e3c-5f4a-41be-9e1e-78b3f9c8f88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# arrange each subjects maps by which encounter num it is\n",
    "all_contrast_maps = defaultdict(lambda: defaultdict(lambda: defaultdict(list)))\n",
    "encounter_maps = defaultdict(lambda: defaultdict(lambda: defaultdict(dict)))\n",
    "\n",
    "for task in TASKS:\n",
    "    for contrast_name in CONTRASTS[task]:\n",
    "        for subject in SUBJECTS:\n",
    "            \n",
    "            overall_encounter_count = 0\n",
    "            \n",
    "            for session in SESSIONS:\n",
    "                contrast_map_path = build_contrast_map_path(BASE_DIR, LEVEL, subject, session, task, contrast_name)\n",
    "                # print(contrast_map_path)\n",
    "                \n",
    "                if os.path.exists(contrast_map_path):\n",
    "                    all_contrast_maps[task][contrast_name][subject].append(contrast_map_path)\n",
    "                    encounter_maps[task][contrast_name][subject][overall_encounter_count] = contrast_map_path\n",
    "                    overall_encounter_count += 1\n",
    "                # else:\n",
    "                #     print(f\"{contrast_map_path} is not found\")\n",
    "\n",
    "first_level_session_maps = all_contrast_maps\n",
    "first_level_encounter_maps = encounter_maps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd240fc2-b33c-4941-afa6-02f7d87ed7a5",
   "metadata": {},
   "source": [
    "# general loading and plotting functions that can apply across all tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6163267f-449a-4d41-8e8f-2b5df76df5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# relevant loading functions taken from 3_create_RSMs_first_level\n",
    "# function to gather maps of a certain task/contrast from first_level_encounter_maps\n",
    "def gather_tc_maps(req_tasks,req_contrasts,all_maps=first_level_encounter_maps,req_encounters=[0,1,2,3,4], req_subjects = SUBJECTS):\n",
    "    '''\n",
    "    Get a list of loaded niftis for specific task/contrast/encounter combinations of first level maps \n",
    "    \n",
    "    Parameters\n",
    "        req_tasks: list of tasks as strings (all tasks have to be from the TASKS dict)\n",
    "        req_contrasts: list of contrasts as strings (all tasks have to be from the CONTRASTS dict)\n",
    "        all_maps: [task][contrast_name][subject][overall_encounter_count] -> one map each (here it is in a filepath format)\n",
    "        req_encounters: list of encounter numbers that are requested (default is all 5)\n",
    "        req_subjects: list of subject id strings that are requested (default is all in SUBJECTS)\n",
    "    Return\n",
    "        specified_maps: list of loaded nifti files that fit the requested task, contrast, and encounter (this returns this for all subjects)\n",
    "        specified_descriptors: list of descriptions of each file (i.e. titles)\n",
    "        data_title: informative title for the RSM that will later be created\n",
    "    \n",
    "    '''\n",
    "    specified_maps = []\n",
    "    specified_descriptors = []\n",
    "    max_num_encounters = 5\n",
    "\n",
    "    if (len(req_tasks) == 0) or (len(req_contrasts) == 0):\n",
    "        return [], [], ''\n",
    "\n",
    "    for task in req_tasks:\n",
    "        if task not in TASKS:\n",
    "            print(f\"task {task} not in task masterlist\")\n",
    "            continue\n",
    "    \n",
    "        for contrast in req_contrasts:\n",
    "            if contrast not in CONTRASTS[task]: # make sure this contrast exists in the given task\n",
    "                print(f\"skipped for contrast {contrast} and task {task}\")\n",
    "                continue\n",
    "                \n",
    "            for subject in req_subjects:\n",
    "                if subject not in SUBJECTS:\n",
    "                    print(f\"subject: {subject} is not in this dataset, so skipped\")\n",
    "                    continue\n",
    "                    \n",
    "                for encounter in req_encounters:\n",
    "                    if encounter < 0 or encounter >= max_num_encounters:\n",
    "                        continue\n",
    "\n",
    "                    descriptor_name = f\"{subject}:encounter-0{encounter + 1}\"\n",
    "                            \n",
    "                    if task in all_maps.keys():\n",
    "                        if contrast in all_maps[task].keys():\n",
    "                            if subject in all_maps[task][contrast].keys():\n",
    "                                if encounter in all_maps[task][contrast][subject].keys():\n",
    "\n",
    "                                    map_data = all_maps[task][contrast][subject][encounter]\n",
    "                                    \n",
    "                                    # Check if file is already loaded\n",
    "                                    if isinstance(map_data, str):\n",
    "                                        # map_data is a file path, need to load it\n",
    "                                        try:\n",
    "                                            if os.path.exists(map_data):\n",
    "                                                loaded_map = nib.load(map_data)\n",
    "                                                specified_maps.append(loaded_map)\n",
    "                                                specified_descriptors.append(descriptor_name)\n",
    "                                            else:\n",
    "                                                print(f\"File not found: {map_data}\")\n",
    "                                                failed_loads.append((descriptor_name, \"File not found\"))\n",
    "                                        except Exception as e:\n",
    "                                            print(f\"Error loading {map_data}: {str(e)}\")\n",
    "                                    else:\n",
    "                                        print(f\"Unexpected data type for {descriptor_name}: {type(map_data)}\")\n",
    "                                        \n",
    "                                else:\n",
    "                                    print(f\"{task}|{contrast}|{subject}: {encounter}\")\n",
    "                                    continue\n",
    "                            else:\n",
    "                                print(f\"{task}|{contrast} subject {subject}\")\n",
    "                                continue\n",
    "                        else:\n",
    "                            print(f\"{task}:{contrast}\")\n",
    "                            continue\n",
    "                    else:\n",
    "                        print(f\"{task}\")\n",
    "                        continue\n",
    "    # create RSM title\n",
    "    data_title = ''\n",
    "    if (len(req_tasks) == 1):\n",
    "        data_title += f'Task:{req_tasks[0]}|'\n",
    "    else:  # more than 1 task\n",
    "        data_title += 'Task:'\n",
    "        for i, task in enumerate(req_tasks):\n",
    "            if (i != len(req_tasks) - 1):\n",
    "                data_title += f\"{task},\"\n",
    "            else:\n",
    "                data_title += f\"{task}\"\n",
    "        data_title += '|'\n",
    "\n",
    "    if (len(req_contrasts) == 1):\n",
    "        data_title += f'Contrast:{req_contrasts[0]}'\n",
    "    else:\n",
    "        data_title += 'Contrast:'\n",
    "        for i, contrast in enumerate(req_contrasts):\n",
    "            if (i != (len(req_contrasts) - 1)):\n",
    "                data_title += f\"{contrast},\"\n",
    "            else:\n",
    "                data_title += f\"{contrast}\"\n",
    "    \n",
    "    return specified_maps, specified_descriptors, data_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34abd7d5-2ab7-4b53-a24d-9ca3370da018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort this by encounter (later move this into the main gather_tc-maps func)\n",
    "def reorganize_dict(original_dict):\n",
    "    new_dict = {}\n",
    "    \n",
    "    for task, contrasts in original_dict.items():\n",
    "        new_dict[task] = {}\n",
    "        \n",
    "        for contrast, data in contrasts.items():\n",
    "            new_dict[task][contrast] = {}\n",
    "            \n",
    "            maps_list = data['maps_list']\n",
    "            descriptors_list = data['descriptors_list']\n",
    "            \n",
    "            # Process each map and its corresponding descriptor\n",
    "            for map_obj, descriptor in zip(maps_list, descriptors_list):\n",
    "                # (e.g., 'sub-s10:encounter-01')\n",
    "                parts = descriptor.split(':')\n",
    "                sub = parts[0]  # 'sub-s10'\n",
    "                encounter = parts[1]  # 'encounter-01'\n",
    "                encounter_num = encounter.split('-')[1]  # '01'\n",
    "                \n",
    "                # Create nested structure if it doesn't exist\n",
    "                if sub not in new_dict[task][contrast]:\n",
    "                    new_dict[task][contrast][sub] = {}\n",
    "                \n",
    "                # Assign the map object to the appropriate location\n",
    "                new_dict[task][contrast][sub][encounter_num] = map_obj\n",
    "    \n",
    "    return new_dict\n",
    "    \n",
    "def gather_tc_maps_full_task(req_tasks_contrasts = requested_task_contrasts, curr_task = None, req_contrasts = None, create_subset=False):\n",
    "    '''\n",
    "    Get a dict of loaded niftis for every contrast of a requested task (uses gather_tc_maps and puts it into a dict organized\n",
    "    by task/contrast). If curr_task or req_contrasts is not None, then just do this for one task (not all task/contrasts in \n",
    "    req_tasks_contrasts)\n",
    "    \n",
    "    Parameters\n",
    "        req_tasks_contrasts = dict of all tasks that we are organizing\n",
    "        curr_task: specific task to load (if create_subset = True) instead of doing it for all task/contrasts\n",
    "        req_contrasts: specific contrasts to load (if create_subset=True and curr_task != None). \n",
    "        create_subset: default False (if true, then don't organize the dict for all task/contrasts, but only for the requested current task and its contrasts).\n",
    "    Return\n",
    "        task_contrast_all_maps[task][contrast] = [\"maps_list\",\"descriptors_list\", \"data_title\"]\n",
    "    '''\n",
    "    task_contrast_all_maps = {}\n",
    "\n",
    "    # if it was just a subset\n",
    "    if ((create_subset) and (curr_task != None)):\n",
    "        if req_contrasts == None:\n",
    "            req_contrasts = req_tasks_contrasts[curr_task]\n",
    "\n",
    "        print(f\"creating a subset dict for {curr_task} and contrasts {req_contrasts.items()}\")\n",
    "\n",
    "        print(\"MISSING:\")\n",
    "        task_contrast_all_maps[curr_task] = {}\n",
    "        for contrast in req_contrasts:\n",
    "            task_contrast_all_maps[curr_task][contrast] = {}\n",
    "            task_contrast_all_maps[curr_task][contrast][\"maps_list\"] = []\n",
    "            task_contrast_all_maps[curr_task][contrast][\"descriptors_list\"] = []\n",
    "            task_contrast_all_maps[curr_task][contrast][\"data_title\"] = \"\"\n",
    "        \n",
    "            req_tasks_tc = [curr_task]\n",
    "            req_contrasts_tc = [contrast]\n",
    "        \n",
    "            task_contrast_all_maps[curr_task][contrast][\"maps_list\"],task_contrast_all_maps[curr_task][contrast][\"descriptors_list\"],task_contrast_all_maps[curr_task][contrast][\"data_title\"] = gather_tc_maps(req_tasks_tc,req_contrasts_tc,all_maps=first_level_encounter_maps,req_encounters=[0,1,2,3,4], req_subjects = SUBJECTS)\n",
    "\n",
    "        return task_contrast_all_maps\n",
    "\n",
    "    # if it was for loading all of the task/contrast combos\n",
    "    for curr_task in req_tasks_contrasts:\n",
    "        task_contrast_all_maps[curr_task] = {}\n",
    "\n",
    "        print(f\"MISSING for {curr_task}:\")\n",
    "        for contrast in req_tasks_contrasts[curr_task]:\n",
    "            task_contrast_all_maps[curr_task][contrast] = {}\n",
    "            task_contrast_all_maps[curr_task][contrast][\"maps_list\"] = []\n",
    "            task_contrast_all_maps[curr_task][contrast][\"descriptors_list\"] = []\n",
    "            task_contrast_all_maps[curr_task][contrast][\"data_title\"] = \"\"\n",
    "        \n",
    "            req_tasks_tc = [curr_task]\n",
    "            req_contrasts_tc = [contrast]\n",
    "        \n",
    "            task_contrast_all_maps[curr_task][contrast][\"maps_list\"],task_contrast_all_maps[curr_task][contrast][\"descriptors_list\"],task_contrast_all_maps[curr_task][contrast][\"data_title\"] = gather_tc_maps(req_tasks_tc,req_contrasts_tc,all_maps=first_level_encounter_maps,req_encounters=[0,1,2,3,4], req_subjects = SUBJECTS)\n",
    "            \n",
    "    return task_contrast_all_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f00848c-95b5-4792-9e7a-0033b4d923b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_mask(mask_img, dtype=bool):\n",
    "    \"\"\"Ensure mask has consistent data type and format\"\"\"\n",
    "    mask_data = mask_img.get_fdata()\n",
    "    # Convert to binary and specified dtype\n",
    "    binary_data = (mask_data > 0).astype(dtype)\n",
    "    return image.new_img_like(mask_img, binary_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7924863c-fa06-4e4f-8350-101e106a8f7a",
   "metadata": {},
   "source": [
    "# Parcellate across all task/contrasts/subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d38730c-28d5-45db-b078-4f7a5c8ecf92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MISSING for nBack:\n",
      "MISSING for flanker:\n",
      "MISSING for directedForgetting:\n",
      "MISSING for goNogo:\n",
      "goNogo|nogo_success-go|sub-s19: 4\n",
      "goNogo|nogo_success-go|sub-s29: 4\n",
      "goNogo|nogo_success-go|sub-s43: 4\n",
      "goNogo|nogo_success|sub-s19: 4\n",
      "goNogo|nogo_success|sub-s29: 4\n",
      "goNogo|nogo_success|sub-s43: 4\n",
      "goNogo|task-baseline|sub-s19: 4\n",
      "goNogo|task-baseline|sub-s29: 4\n",
      "goNogo|task-baseline|sub-s43: 4\n",
      "goNogo|response_time|sub-s19: 4\n",
      "goNogo|response_time|sub-s29: 4\n",
      "goNogo|response_time|sub-s43: 4\n",
      "MISSING for shapeMatching:\n",
      "MISSING for stopSignal:\n",
      "MISSING for cuedTS:\n",
      "cuedTS|cue_switch_cost|sub-s29: 4\n",
      "cuedTS|task_switch_cost|sub-s29: 4\n",
      "cuedTS|task_switch_cue_switch-task_stay_cue_stay|sub-s29: 4\n",
      "cuedTS|task-baseline|sub-s29: 4\n",
      "cuedTS|response_time|sub-s29: 4\n",
      "MISSING for spatialTS:\n"
     ]
    }
   ],
   "source": [
    "# load all of the maps in an organized dict and see which maps are missing per task\n",
    "task_contrast_all_maps = gather_tc_maps_full_task(req_tasks_contrasts = requested_task_contrasts,create_subset=False)\n",
    "\n",
    "# Use the function\n",
    "task_contrast_enc_all_maps = reorganize_dict(task_contrast_all_maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c372261-ff24-4d08-8694-9ee3a573da07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Smorgasbord atlas...\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "# 1. Load the Smorgasbord atlas\n",
    "print(\"Loading Smorgasbord atlas...\")\n",
    "\n",
    "# Load the NIfTI file\n",
    "atlas_img = nib.load('smor_parcel_dfs/smorgasbord_atlas_files/tpl-MNI152NLin2009cAsym_res-01_atlas-smorgasbord_dseg.nii')\n",
    "\n",
    "# Load the labels from TSV\n",
    "labels_df = pd.read_csv('smor_parcel_dfs/smorgasbord_atlas_files/tpl-MNI152NLin2009cAsym_res-01_atlas-smorgasbord_dseg.tsv', sep='\\t')\n",
    "\n",
    "# Extract labels as a list\n",
    "labels = labels_df['name'].tolist()\n",
    "\n",
    "# Create a Bunch object to make it the same format as Schaefer\n",
    "smorgasbord_atlas = Bunch(\n",
    "    maps=atlas_img,\n",
    "    labels=labels,\n",
    "    description='Smorgasbord atlas from GitHub'\n",
    ")\n",
    "print(\"done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a64c897b-b2b1-46bb-b5e2-34d1d2a83645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Atlas data shape: (193, 229, 193)\n",
      "Unique ROI values: 430\n",
      "ROI range: 0.0 to 606.0\n",
      "\n",
      "Number of unique ROIs (excluding 0/background): 429\n",
      "Number of labels: 429\n",
      "\n",
      "First 5 labels:\n",
      "  0: 7Networks_LH_Vis_1\n",
      "  1: 7Networks_LH_Vis_2\n",
      "  2: 7Networks_LH_Vis_3\n",
      "  3: 7Networks_LH_Vis_4\n",
      "  4: 7Networks_LH_Vis_5\n"
     ]
    }
   ],
   "source": [
    "# Check the atlas data\n",
    "atlas_data = smorgasbord_atlas.maps.get_fdata()\n",
    "print(f\"Atlas data shape: {atlas_data.shape}\")\n",
    "print(f\"Unique ROI values: {len(np.unique(atlas_data))}\")\n",
    "print(f\"ROI range: {atlas_data.min()} to {atlas_data.max()}\")\n",
    "\n",
    "# Check if number of labels matches number of ROIs\n",
    "unique_rois = np.unique(atlas_data)\n",
    "print(f\"\\nNumber of unique ROIs (excluding 0/background): {len(unique_rois[unique_rois > 0])}\")\n",
    "print(f\"Number of labels: {len(smorgasbord_atlas.labels)}\")\n",
    "\n",
    "# Inspect first few labels\n",
    "print(f\"\\nFirst 5 labels:\")\n",
    "for i in range(5):\n",
    "    print(f\"  {i}: {smorgasbord_atlas.labels[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30b3587b-ea1f-4ebc-b489-67f4ed66e694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROI values range: 1.0 to 606.0\n",
      "First 10 ROI values: [ 1.  2.  3.  4.  5.  6.  7.  8.  9. 10.]\n",
      "Last 10 ROI values: [517. 518. 519. 521. 601. 602. 603. 604. 605. 606.]\n",
      "\n",
      "ROI value 1 -> 7Networks_LH_Vis_1\n",
      "ROI value 606 -> amygdala_basolateral_right\n"
     ]
    }
   ],
   "source": [
    "# Get actual ROI values\n",
    "atlas_data = smorgasbord_atlas.maps.get_fdata()\n",
    "roi_values = np.unique(atlas_data)\n",
    "roi_values = roi_values[roi_values > 0]  # Remove background (0)\n",
    "\n",
    "print(f\"ROI values range: {roi_values.min()} to {roi_values.max()}\")\n",
    "print(f\"First 10 ROI values: {roi_values[:10]}\")\n",
    "print(f\"Last 10 ROI values: {roi_values[-10:]}\")\n",
    "\n",
    "# Create a mapping from ROI value to label\n",
    "roi_to_label = dict(zip(roi_values, smorgasbord_atlas.labels))\n",
    "\n",
    "# Example: What label corresponds to ROI value 1?\n",
    "print(f\"\\nROI value 1 -> {roi_to_label.get(1, 'Not found')}\")\n",
    "print(f\"ROI value 606 -> {roi_to_label.get(606, 'Not found')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f74c2e7a-a6df-48ee-b91b-a0ccee2820bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the ROI-to-label mapping to your atlas\n",
    "smorgasbord_atlas.roi_values = roi_values\n",
    "smorgasbord_atlas.roi_to_label = roi_to_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71ce52f2-30cc-43d9-8935-88acb17b9072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the entire Bunch object with all additions\n",
    "with open('smor_parcel_dfs/smorgasbord_atlas_files/smorgasbord_atlas.pkl', 'wb') as f:\n",
    "    pickle.dump(smorgasbord_atlas, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62aeee5e-5eee-466e-8e11-08f4fc6df681",
   "metadata": {},
   "outputs": [],
   "source": [
    "encounters = ['01', '02','03','04','05']\n",
    "\n",
    "def save_subset_of_parcels(subs_requested, run_num, atlas='schaefer'):\n",
    "    \"\"\"\n",
    "    Extract parcel-wise activation values from fMRI contrast maps.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    subs_requested : list\n",
    "        Subject IDs to process\n",
    "    run_num : str/int\n",
    "        Run identifier for output filename\n",
    "    atlas : str or Bunch\n",
    "        Either 'schaefer' or a custom atlas Bunch object (e.g., smorgasbord_atlas)\n",
    "    \"\"\"\n",
    "    parcel_dict = {}\n",
    "    \n",
    "    # Select atlas\n",
    "    if atlas == 'schaefer':\n",
    "        current_atlas = schaefer_atlas\n",
    "        atlas_name = 'schaefer400'\n",
    "    else:\n",
    "        current_atlas = atlas\n",
    "        atlas_name = 'smor_parcel'\n",
    "\n",
    "    for curr_subj in subs_requested:   \n",
    "        parcel_dict[curr_subj] = {}\n",
    "        \n",
    "        for curr_task in requested_task_contrasts:\n",
    "            parcel_dict[curr_subj][curr_task] = {}\n",
    "    \n",
    "            for curr_contrast in requested_task_contrasts[curr_task]:\n",
    "                parcel_dict[curr_subj][curr_task][curr_contrast] = {}\n",
    "    \n",
    "                for enc in encounters:\n",
    "                    print(f\"Processing: {curr_subj} - {curr_task} - {curr_contrast} - Enc {enc}\")\n",
    "    \n",
    "                    try:\n",
    "                        fmri_img = task_contrast_enc_all_maps[curr_task][curr_contrast][curr_subj][enc]\n",
    "                        print(f\"fMRI data loaded | Shape: {fmri_img.shape}\")\n",
    "        \n",
    "                        # Create the masker and get regional avg activation\n",
    "                        masker = NiftiLabelsMasker(\n",
    "                            labels_img=current_atlas.maps,\n",
    "                            standardize=False, \n",
    "                            memory='nilearn_cache',\n",
    "                            strategy='mean'  # Average activation within each region\n",
    "                        )\n",
    "                        \n",
    "                        # Extract regional values\n",
    "                        regional_values = masker.fit_transform(fmri_img)\n",
    "                        \n",
    "                        # Handle labels (decode if bytes)\n",
    "                        region_labels = [\n",
    "                            label.decode('utf-8') if isinstance(label, bytes) else label \n",
    "                            for label in current_atlas.labels\n",
    "                        ]\n",
    "                        \n",
    "                        # Create activation dataframe\n",
    "                        activation_df = pd.DataFrame({\n",
    "                            'region': region_labels,\n",
    "                            'activation': regional_values.flatten()\n",
    "                        })\n",
    "                        \n",
    "                        # Add network information (handle both Schaefer and other atlases)\n",
    "                        activation_df['network'] = activation_df['region'].apply(\n",
    "                            lambda x: x.split('_')[1] if 'Networks' in x else 'Subcortical'\n",
    "                        )\n",
    "                        \n",
    "                        # Add ROI values if available (for smorgasbord atlas)\n",
    "                        if hasattr(current_atlas, 'roi_values'):\n",
    "                            activation_df['roi_value'] = current_atlas.roi_values\n",
    "                        \n",
    "                        # Save the activation df\n",
    "                        parcel_dict[curr_subj][curr_task][curr_contrast][enc] = activation_df\n",
    "                        print(f\"Extracted {len(activation_df)} regions\")\n",
    "                        \n",
    "                    except KeyError as e:\n",
    "                        print(f\"Warning: Data not found - Missing key: {e}\")\n",
    "                        parcel_dict[curr_subj][curr_task][curr_contrast][enc] = None\n",
    "                        continue\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error processing data: {str(e)}\")\n",
    "                        parcel_dict[curr_subj][curr_task][curr_contrast][enc] = None\n",
    "                        continue\n",
    "\n",
    "    # Save to pickle\n",
    "    output_dir = f'{atlas_name}_dfs'\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    output_file = f'{output_dir}/discovery_parcel_indiv_mean_updated_1027_{run_num}.pkl'\n",
    "    with open(output_file, 'wb') as f:\n",
    "        pickle.dump(parcel_dict, f)\n",
    "    \n",
    "    print(f\"\\nSaved to: {output_file}\")\n",
    "    \n",
    "    # Delete from cache\n",
    "    del parcel_dict\n",
    "    cleanup_memory()\n",
    "\n",
    "# With Smorgasbord atlas\n",
    "# save_subset_of_parcels(subject_list, run_num=1, atlas=smorgasbord_atlas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7663cf66-43cc-4194-bf4f-1f593894e900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get first 2 subjects and save\n",
    "save_subset_of_parcels(SUBJECTS[0:2], 1, atlas=smorgasbord_atlas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92085f6-1472-4834-8baa-90b2e45d3988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get next 2 subjects and save\n",
    "save_subset_of_parcels(SUBJECTS[2:4], 2, atlas=smorgasbord_atlas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95d549c-79fd-4844-a6f7-1d6bd04e7412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: sub-s43 - nBack - twoBack-oneBack - Enc 01\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - nBack - twoBack-oneBack - Enc 02\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - nBack - twoBack-oneBack - Enc 03\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - nBack - twoBack-oneBack - Enc 04\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - nBack - twoBack-oneBack - Enc 05\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - nBack - match-mismatch - Enc 01\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - nBack - match-mismatch - Enc 02\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - nBack - match-mismatch - Enc 03\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - nBack - match-mismatch - Enc 04\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - nBack - match-mismatch - Enc 05\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - nBack - task-baseline - Enc 01\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - nBack - task-baseline - Enc 02\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - nBack - task-baseline - Enc 03\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - nBack - task-baseline - Enc 04\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - nBack - task-baseline - Enc 05\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - nBack - response_time - Enc 01\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - nBack - response_time - Enc 02\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - nBack - response_time - Enc 03\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - nBack - response_time - Enc 04\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - nBack - response_time - Enc 05\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - flanker - incongruent-congruent - Enc 01\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - flanker - incongruent-congruent - Enc 02\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - flanker - incongruent-congruent - Enc 03\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - flanker - incongruent-congruent - Enc 04\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - flanker - incongruent-congruent - Enc 05\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - flanker - task-baseline - Enc 01\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - flanker - task-baseline - Enc 02\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - flanker - task-baseline - Enc 03\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - flanker - task-baseline - Enc 04\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - flanker - task-baseline - Enc 05\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - directedForgetting - neg-con - Enc 01\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - directedForgetting - neg-con - Enc 02\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - directedForgetting - neg-con - Enc 03\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - directedForgetting - neg-con - Enc 04\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - directedForgetting - neg-con - Enc 05\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - directedForgetting - task-baseline - Enc 01\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - directedForgetting - task-baseline - Enc 02\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - directedForgetting - task-baseline - Enc 03\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - directedForgetting - task-baseline - Enc 04\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - directedForgetting - task-baseline - Enc 05\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - directedForgetting - response_time - Enc 01\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - directedForgetting - response_time - Enc 02\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - directedForgetting - response_time - Enc 03\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - directedForgetting - response_time - Enc 04\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - directedForgetting - response_time - Enc 05\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - goNogo - nogo_success-go - Enc 01\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - goNogo - nogo_success-go - Enc 02\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - goNogo - nogo_success-go - Enc 03\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - goNogo - nogo_success-go - Enc 04\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - goNogo - nogo_success-go - Enc 05\n",
      "Warning: Data not found - Missing key: '05'\n",
      "Processing: sub-s43 - goNogo - nogo_success - Enc 01\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - goNogo - nogo_success - Enc 02\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - goNogo - nogo_success - Enc 03\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - goNogo - nogo_success - Enc 04\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - goNogo - nogo_success - Enc 05\n",
      "Warning: Data not found - Missing key: '05'\n",
      "Processing: sub-s43 - goNogo - task-baseline - Enc 01\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - goNogo - task-baseline - Enc 02\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - goNogo - task-baseline - Enc 03\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - goNogo - task-baseline - Enc 04\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - goNogo - task-baseline - Enc 05\n",
      "Warning: Data not found - Missing key: '05'\n",
      "Processing: sub-s43 - goNogo - response_time - Enc 01\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - goNogo - response_time - Enc 02\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - goNogo - response_time - Enc 03\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - goNogo - response_time - Enc 04\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - goNogo - response_time - Enc 05\n",
      "Warning: Data not found - Missing key: '05'\n",
      "Processing: sub-s43 - shapeMatching - DDD - Enc 01\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - shapeMatching - DDD - Enc 02\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - shapeMatching - DDD - Enc 03\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - shapeMatching - DDD - Enc 04\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - shapeMatching - DDD - Enc 05\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - shapeMatching - DDS - Enc 01\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - shapeMatching - DDS - Enc 02\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - shapeMatching - DDS - Enc 03\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - shapeMatching - DDS - Enc 04\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - shapeMatching - DDS - Enc 05\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - shapeMatching - DNN - Enc 01\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - shapeMatching - DNN - Enc 02\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - shapeMatching - DNN - Enc 03\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - shapeMatching - DNN - Enc 04\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - shapeMatching - DNN - Enc 05\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - shapeMatching - DSD - Enc 01\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - shapeMatching - DSD - Enc 02\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - shapeMatching - DSD - Enc 03\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - shapeMatching - DSD - Enc 04\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - shapeMatching - DSD - Enc 05\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - shapeMatching - main_vars - Enc 01\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - shapeMatching - main_vars - Enc 02\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - shapeMatching - main_vars - Enc 03\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - shapeMatching - main_vars - Enc 04\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - shapeMatching - main_vars - Enc 05\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - shapeMatching - SDD - Enc 01\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - shapeMatching - SDD - Enc 02\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - shapeMatching - SDD - Enc 03\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - shapeMatching - SDD - Enc 04\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - shapeMatching - SDD - Enc 05\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - shapeMatching - SNN - Enc 01\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - shapeMatching - SNN - Enc 02\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - shapeMatching - SNN - Enc 03\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - shapeMatching - SNN - Enc 04\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - shapeMatching - SNN - Enc 05\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - shapeMatching - SSS - Enc 01\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - shapeMatching - SSS - Enc 02\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - shapeMatching - SSS - Enc 03\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - shapeMatching - SSS - Enc 04\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - shapeMatching - SSS - Enc 05\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - shapeMatching - task-baseline - Enc 01\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - shapeMatching - task-baseline - Enc 02\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - shapeMatching - task-baseline - Enc 03\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - shapeMatching - task-baseline - Enc 04\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - shapeMatching - task-baseline - Enc 05\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - shapeMatching - response_time - Enc 01\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - shapeMatching - response_time - Enc 02\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - shapeMatching - response_time - Enc 03\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - shapeMatching - response_time - Enc 04\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n",
      "Extracted 429 regions\n",
      "Processing: sub-s43 - shapeMatching - response_time - Enc 05\n",
      "fMRI data loaded | Shape: (97, 115, 97)\n"
     ]
    }
   ],
   "source": [
    "# get last subject and save\n",
    "save_subset_of_parcels([SUBJECTS[-1]], 3, atlas=smorgasbord_atlas)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (PDM Environment)",
   "language": "python",
   "name": "pdm-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
