{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31f85be-4d45-4caa-bd53-fe6da37b382c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizes the parcellated results from step 9 (using schaefer 400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c02c99-d027-403b-ae70-b7f410edbfa3",
   "metadata": {},
   "source": [
    "# imports and general helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5764d3e2-e9a1-4fd8-9cf4-0f786cd473bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "import nilearn\n",
    "import json\n",
    "import datetime\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import gc\n",
    "import psutil\n",
    "import math\n",
    "import scipy.stats as stats\n",
    "from matplotlib.patches import Patch\n",
    "from nilearn import plotting\n",
    "from nilearn.glm.first_level import FirstLevelModel\n",
    "from nilearn.glm.second_level import SecondLevelModel\n",
    "from nilearn.glm import threshold_stats_img\n",
    "from nilearn.image import concat_imgs, mean_img, index_img\n",
    "from nilearn.reporting import make_glm_report\n",
    "from nilearn import masking, image\n",
    "from nilearn import datasets\n",
    "from scipy.stats import pearsonr\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from nilearn.maskers import NiftiLabelsMasker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c10cf3db-8392-4f1b-92f1-044ed3248816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general helper functions:\n",
    "def build_contrast_map_path(base_dir, level, subject, session, task, contrast_name):\n",
    "    \"\"\"Build the file path for a contrast map.\"\"\"\n",
    "    filename = f'{subject}_{session}_task-{task}_contrast-{contrast_name}_rtmodel-rt_centered_stat-effect-size.nii.gz'\n",
    "    \n",
    "    # NOTE: as of 7/6/25 for sub 10 in flanker the format is different: sub-s10_ses-01_run-1_task-flanker_contrast-incongruent-congruent_rtmodel-rt_centered_stat-effect-size.nii.gz\n",
    "    if (subject == 'sub-s10' and task == 'flanker'):\n",
    "        filename = f'{subject}_{session}_run-1_task-{task}_contrast-{contrast_name}_rtmodel-rt_centered_stat-effect-size.nii.gz'\n",
    "        \n",
    "    return os.path.join(base_dir, level, subject, task, 'indiv_contrasts', filename)\n",
    "\n",
    "def is_valid_contrast_map(img_path):\n",
    "    \"\"\"Check if a contrast map has sufficient variance and no NaN values.\"\"\"\n",
    "    try:\n",
    "        img = nib.load(img_path)\n",
    "        data = img.get_fdata()\n",
    "        return np.std(data) > 1e-10 and not np.isnan(data).any()\n",
    "    except Exception as e:\n",
    "        print(f\"Error validating {img_path}: {e}\")\n",
    "        return False\n",
    "        \n",
    "def clean_z_map_data(z_map, task, contrast_name, encounter):\n",
    "    \"\"\"Clean z-map data by handling NaN and infinity values.\"\"\"\n",
    "    data = z_map.get_fdata()\n",
    "    if np.isnan(data).any() or np.isinf(data).any():\n",
    "        data = np.nan_to_num(data)\n",
    "        z_map = nib.Nifti1Image(data, z_map.affine, z_map.header)\n",
    "        print(f\"Warning: Fixed NaN/Inf values in {task}:{contrast_name}:encounter-{encounter+1}\")\n",
    "    return z_map\n",
    "\n",
    "def cleanup_memory():\n",
    "    \"\"\"\n",
    "    Clean up memory between batches\n",
    "    \"\"\"\n",
    "    # Force garbage collection\n",
    "    gc.collect()\n",
    "    \n",
    "    # Get memory info\n",
    "    memory = psutil.virtual_memory()\n",
    "    print(f\"Memory after cleanup: {memory.percent:.1f}% used ({memory.available/(1024**3):.1f}GB available)\")\n",
    "def convert_to_regular_dict(d):\n",
    "    if isinstance(d, defaultdict):\n",
    "        return {k: convert_to_regular_dict(v) for k, v in d.items()}\n",
    "    elif isinstance(d, list):\n",
    "        return [convert_to_regular_dict(i) for i in d]\n",
    "    else:\n",
    "        return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f9e1ae6b-e00a-41fc-a332-5ffa5ec597ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all tasks and contrasts\n",
    "TASKS = [\"nBack\",\"flanker\",\"directedForgetting\",\"goNogo\", \"shapeMatching\", \"stopSignal\", \"cuedTS\", \"spatialTS\"]\n",
    "CONTRASTS = {}\n",
    "CONTRASTS[\"nBack\"] = [\"twoBack-oneBack\", \"match-mismatch\",\"task-baseline\",\"response_time\"] # the nback contrasts\n",
    "CONTRASTS[\"flanker\"] = [\"incongruent-congruent\", \"task-baseline\"]\n",
    "CONTRASTS[\"directedForgetting\"] = [\"neg-con\", \"task-baseline\",\"response_time\"]\n",
    "CONTRASTS[\"goNogo\"] = [\"nogo_success-go\", \"nogo_success\",\"task-baseline\",\"response_time\"] # go_rtModel check\n",
    "CONTRASTS[\"shapeMatching\"] = [\"DDD\", \"DDS\", \"DNN\", \"DSD\", \"main_vars\", \"SDD\", \"SNN\", \"SSS\", \"task-baseline\",\"response_time\"]\n",
    "CONTRASTS[\"stopSignal\"] = [\"go\", \"stop_failure-go\", \"stop_failure\", \"stop_failure-stop_success\", \"stop_success-go\", \"stop_success\", \"stop_success-stop_failure\", \"task-baseline\",\"response_time\"]\n",
    "CONTRASTS[\"cuedTS\"] = [\"cue_switch_cost\", \"task_switch_cost\", \"task_switch_cue_switch-task_stay_cue_stay\", \"task-baseline\",\"response_time\"]\n",
    "CONTRASTS[\"spatialTS\"] = [\"cue_switch_cost\", \"task_switch_cost\", \"task_switch_cue_switch-task_stay_cue_stay\", \"task-baseline\",\"response_time\"]\n",
    "\n",
    "# main conditions and contrasts that we're interested in looking at\n",
    "requested_task_contrasts = defaultdict(lambda: defaultdict(list))\n",
    "requested_task_contrasts['nBack'] = [\"twoBack-oneBack\", 'task-baseline']\n",
    "requested_task_contrasts['flanker'] = [\"incongruent-congruent\",'task-baseline']\n",
    "requested_task_contrasts['directedForgetting'] = [\"neg-con\",'task-baseline']\n",
    "requested_task_contrasts['goNogo'] = [\"nogo_success-go\",'task-baseline']\n",
    "requested_task_contrasts['shapeMatching'] = [\"main_vars\",'task-baseline']\n",
    "requested_task_contrasts['stopSignal'] = [\"stop_failure-go\",'task-baseline']\n",
    "requested_task_contrasts['cuedTS'] = [\"task_switch_cost\",'task-baseline']\n",
    "requested_task_contrasts['spatialTS'] = [\"task_switch_cost\",'task-baseline']\n",
    "\n",
    "compiled_req_contrasts = [\"twoBack-oneBack\", 'task-baseline', \"incongruent-congruent\", \"neg-con\", \"nogo_success-go\", \"main_vars\", \"stop_failure-go\",\"task_switch_cost\"]\n",
    "\n",
    "ENCOUNTERS = ['01', '02','03','04','05']\n",
    "SUBJECTS = ['sub-s03', 'sub-s10', 'sub-s19', 'sub-s29', 'sub-s43']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb83b52d-1797-4758-bed4-8977556cdaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCHAFER_PARCELLATED_DIR = 'schafer400_dfs'\n",
    "schafer_files = {'mean':'discovery_parcel_mean_924.pkl'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9817239-6e5a-4a4f-b5e5-520369d719a8",
   "metadata": {},
   "source": [
    "# load the df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "08cbc774-8b1e-4d51-b0de-7828f3453015",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_filename = f\"{SCHAFER_PARCELLATED_DIR}/{schafer_files['mean']}\"\n",
    "with open(mean_filename, 'rb') as f:\n",
    "    loaded_mean_parcel_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "52117364-f8e8-4aaf-a9a2-5b9a0b3b353b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             region  activation network\n",
      "0                7Networks_LH_Vis_1    0.086090      LH\n",
      "1                7Networks_LH_Vis_2    0.244737      LH\n",
      "2                7Networks_LH_Vis_3    0.229025      LH\n",
      "3                7Networks_LH_Vis_4   -0.175264      LH\n",
      "4                7Networks_LH_Vis_5   -0.102105      LH\n",
      "..                              ...         ...     ...\n",
      "395  7Networks_RH_Default_pCunPCC_5    0.390901      RH\n",
      "396  7Networks_RH_Default_pCunPCC_6    0.262363      RH\n",
      "397  7Networks_RH_Default_pCunPCC_7    0.311818      RH\n",
      "398  7Networks_RH_Default_pCunPCC_8    0.228172      RH\n",
      "399  7Networks_RH_Default_pCunPCC_9    0.111930      RH\n",
      "\n",
      "[400 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(loaded_mean_parcel_dict['sub-s19']['nBack']['twoBack-oneBack']['01'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd91156-587a-4ee7-9b09-69d6fee77fb0",
   "metadata": {},
   "source": [
    "# relevant parcel analysis functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bc9e5a81-67a9-4fb2-8499-43d1e4852423",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_parcel_practice_effects(parcel_dict, subject, task, contrast, encounters_str = ENCOUNTERS):\n",
    "    \"\"\"\n",
    "    Detailed analysis of practice effects for individual parcels\n",
    "\n",
    "    inputs:\n",
    "    parcel_dict: a dict with format subject: task: contrast: encounter: and then the dict of mean activations per parcel (along with region label per parcel)\n",
    "    subject: subject id to parse their parcel trajectories\n",
    "    task: task to look at\n",
    "    contrast: contrast to look at\n",
    "    encounters: by default its 1-5 (the constant); these are the ones being included in the trajectory calculations\n",
    "    \n",
    "    \"\"\"\n",
    "    print(f\"{subject}/{task}/{contrast}\")\n",
    "    # Get all individual parcels\n",
    "    first_encounter = parcel_dict[subject][task][contrast][encounters_str[0]]\n",
    "    all_parcels = first_encounter['region'].tolist()\n",
    "    encounters = [1,2,3,4,5]\n",
    "    parcel_results = {}\n",
    "    \n",
    "    for parcel in all_parcels:\n",
    "        # Extract trajectory for this specific parcel\n",
    "        trajectory = []\n",
    "        \n",
    "        for enc_num, enc in enumerate(encounters_str, 1):\n",
    "            df = parcel_dict[subject][task][contrast][enc]\n",
    "            activation = df[df['region'] == parcel]['activation'].iloc[0]\n",
    "\n",
    "            try:\n",
    "                activation = float(activation)\n",
    "            except (ValueError, TypeError):\n",
    "                print(f\"Warning: Could not convert activation '{activation}' to float for {subject}/{task}/{contrast}/{enc}/{parcel}\")\n",
    "                activation = 0.0\n",
    "            \n",
    "            # activation = df[df['region'] == parcel]['activation']\n",
    "            trajectory.append(activation)\n",
    "        \n",
    "        trajectory = np.array(trajectory, dtype=float)  # Ensure numeric array\n",
    "        \n",
    "        # Statistical analysis\n",
    "        slope, intercept, r_value, p_value, std_err = stats.linregress(encounters, trajectory)\n",
    "        \n",
    "        # Calculate additional metrics\n",
    "        initial_activation = trajectory[0]\n",
    "        final_activation = trajectory[-1]\n",
    "        max_activation = np.max(trajectory)\n",
    "        min_activation = np.min(trajectory)\n",
    "        \n",
    "        # Effect size calculations\n",
    "        if abs(initial_activation) > 0.001:\n",
    "            percent_change = ((final_activation - initial_activation) / abs(initial_activation)) * 100\n",
    "        else:\n",
    "            percent_change = 0\n",
    "        \n",
    "        # Cohen's d for effect size\n",
    "        trajectory_std = np.std(trajectory)\n",
    "        if trajectory_std > 0:\n",
    "            cohens_d = abs(final_activation - initial_activation) / trajectory_std\n",
    "        else:\n",
    "            cohens_d = 0\n",
    "        \n",
    "        # Classification\n",
    "        significant_change = (p_value < 0.05)\n",
    "        large_change = significant_change and (abs(percent_change) > 10)\n",
    "        \n",
    "        parcel_results[parcel] = {\n",
    "            'trajectory': trajectory,\n",
    "            'slope': slope,\n",
    "            'intercept': intercept,\n",
    "            'r_squared': r_value**2,\n",
    "            'p_value': p_value,\n",
    "            'std_error': std_err,\n",
    "            'initial_activation': initial_activation,\n",
    "            'final_activation': final_activation,\n",
    "            'percent_change': percent_change,\n",
    "            'cohens_d': cohens_d,\n",
    "            'max_activation': max_activation,\n",
    "            'min_activation': min_activation,\n",
    "            'activation_range': max_activation - min_activation,\n",
    "            'significant_change': significant_change,\n",
    "            'large_change': large_change,\n",
    "            # 'network': df[df['region'] == parcel]['network'].iloc[0]\n",
    "        }\n",
    "    \n",
    "    return parcel_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "682f4340-33f9-404e-9145-0ff02dbfb995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub-s10/nBack/twoBack-oneBack\n",
      "sub-s10/nBack/task-baseline\n",
      "sub-s10/flanker/incongruent-congruent\n",
      "sub-s10/flanker/task-baseline\n",
      "sub-s10/directedForgetting/neg-con\n",
      "sub-s10/directedForgetting/task-baseline\n",
      "sub-s10/goNogo/nogo_success-go\n",
      "sub-s10/goNogo/task-baseline\n",
      "sub-s10/shapeMatching/main_vars\n",
      "sub-s10/shapeMatching/task-baseline\n",
      "sub-s10/stopSignal/stop_failure-go\n",
      "sub-s10/stopSignal/task-baseline\n",
      "sub-s10/cuedTS/task_switch_cost\n",
      "sub-s10/cuedTS/task-baseline\n",
      "sub-s10/spatialTS/task_switch_cost\n",
      "sub-s10/spatialTS/task-baseline\n",
      "sub-s19/nBack/twoBack-oneBack\n",
      "sub-s19/nBack/task-baseline\n",
      "sub-s19/flanker/incongruent-congruent\n",
      "sub-s19/flanker/task-baseline\n",
      "sub-s19/directedForgetting/neg-con\n",
      "sub-s19/directedForgetting/task-baseline\n",
      "sub-s19/goNogo/nogo_success-go\n",
      "Error processing sub-s19/goNogo/nogo_success-go: '05'\n",
      "sub-s19/goNogo/task-baseline\n",
      "Error processing sub-s19/goNogo/task-baseline: '05'\n",
      "sub-s19/shapeMatching/main_vars\n",
      "sub-s19/shapeMatching/task-baseline\n",
      "sub-s19/stopSignal/stop_failure-go\n",
      "sub-s19/stopSignal/task-baseline\n",
      "sub-s19/cuedTS/task_switch_cost\n",
      "sub-s19/cuedTS/task-baseline\n",
      "sub-s19/spatialTS/task_switch_cost\n",
      "sub-s19/spatialTS/task-baseline\n",
      "sub-s29/nBack/twoBack-oneBack\n",
      "sub-s29/nBack/task-baseline\n",
      "sub-s29/flanker/incongruent-congruent\n",
      "sub-s29/flanker/task-baseline\n",
      "sub-s29/directedForgetting/neg-con\n",
      "sub-s29/directedForgetting/task-baseline\n",
      "sub-s29/goNogo/nogo_success-go\n",
      "Error processing sub-s29/goNogo/nogo_success-go: '05'\n",
      "sub-s29/goNogo/task-baseline\n",
      "Error processing sub-s29/goNogo/task-baseline: '05'\n",
      "sub-s29/shapeMatching/main_vars\n",
      "sub-s29/shapeMatching/task-baseline\n",
      "sub-s29/stopSignal/stop_failure-go\n",
      "sub-s29/stopSignal/task-baseline\n",
      "sub-s29/cuedTS/task_switch_cost\n",
      "Error processing sub-s29/cuedTS/task_switch_cost: '05'\n",
      "sub-s29/cuedTS/task-baseline\n",
      "Error processing sub-s29/cuedTS/task-baseline: '05'\n",
      "sub-s29/spatialTS/task_switch_cost\n",
      "sub-s29/spatialTS/task-baseline\n",
      "sub-s43/nBack/twoBack-oneBack\n",
      "sub-s43/nBack/task-baseline\n",
      "sub-s43/flanker/incongruent-congruent\n",
      "sub-s43/flanker/task-baseline\n",
      "sub-s43/directedForgetting/neg-con\n",
      "sub-s43/directedForgetting/task-baseline\n",
      "sub-s43/goNogo/nogo_success-go\n",
      "Error processing sub-s43/goNogo/nogo_success-go: '05'\n",
      "sub-s43/goNogo/task-baseline\n",
      "Error processing sub-s43/goNogo/task-baseline: '05'\n",
      "sub-s43/shapeMatching/main_vars\n",
      "sub-s43/shapeMatching/task-baseline\n",
      "sub-s43/stopSignal/stop_failure-go\n",
      "sub-s43/stopSignal/task-baseline\n",
      "sub-s43/cuedTS/task_switch_cost\n",
      "sub-s43/cuedTS/task-baseline\n",
      "sub-s43/spatialTS/task_switch_cost\n",
      "sub-s43/spatialTS/task-baseline\n"
     ]
    }
   ],
   "source": [
    "# get the parcel trajectory results per subject\n",
    "parcel_traj_results = {}\n",
    "for subj in SUBJECTS:\n",
    "    if (subj == \"sub-s03\"):\n",
    "        continue\n",
    "    parcel_traj_results[subj] = {}\n",
    "\n",
    "    for task in requested_task_contrasts:\n",
    "        parcel_traj_results[subj][task] = {}\n",
    "\n",
    "        for contrast in requested_task_contrasts[task]:\n",
    "            try:\n",
    "                parcel_traj_results[subj][task][contrast] = analyze_parcel_practice_effects(\n",
    "                    loaded_mean_parcel_dict, subj, task, contrast\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {subj}/{task}/{contrast}: {e}\")\n",
    "                continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003485a1-5f03-40f3-9a06-cbd6d60d1d5d",
   "metadata": {},
   "source": [
    "# visualization functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d7a829-6cfb-4d28-9cad-3f9baccf79a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_parcel_practice_heatmap(parcel_traj):\n",
    "    \"\"\"\n",
    "    Create a heatmap showing practice effects across all parcels\n",
    "\n",
    "    input:\n",
    "    parcel_traj: a df of parcels and activations \n",
    "    title: the title for this heatmap\n",
    "    \"\"\"\n",
    "    \n",
    "    # Prepare data for heatmap\n",
    "    df = pd.DataFrame(parcel_traj).T\n",
    "    \n",
    "    # Sort by slope\n",
    "    df_sorted = df.sort_values(['slope'])\n",
    "    \n",
    "    # Create trajectory matrix\n",
    "    trajectory_matrix = np.array([row['trajectory'] for _, row in df_sorted.iterrows()])\n",
    "    \n",
    "    # Create the heatmap\n",
    "    plt.figure(figsize=(30, 12))\n",
    "    \n",
    "    # Plot trajectories\n",
    "    sns.heatmap(trajectory_matrix, \n",
    "                xticklabels=['Enc 1', 'Enc 2', 'Enc 3', 'Enc 4', 'Enc 5'],\n",
    "                yticklabels=[row.name.split('_')[-1] for _, row in df_sorted.iterrows()],\n",
    "                cmap='RdBu_r', center=0, \n",
    "                cbar_kws={'label': 'Activation'})\n",
    "    \n",
    "    plt.title('Practice Effects Across All Parcels')\n",
    "    plt.xlabel('Encounter')\n",
    "    plt.ylabel('Brain Parcels (sorted by network)')\n",
    "    \n",
    "    # Add network boundaries\n",
    "    networks = df_sorted['network'].values\n",
    "    boundaries = []\n",
    "    current_network = networks[0]\n",
    "    \n",
    "    for i, network in enumerate(networks[1:], 1):\n",
    "        if network != current_network:\n",
    "            boundaries.append(i)\n",
    "            current_network = network\n",
    "    \n",
    "    for boundary in boundaries:\n",
    "        plt.axhline(y=boundary, color='white', linewidth=2)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98650783-7228-493b-9bba-f300837a5f82",
   "metadata": {},
   "source": [
    "# individual analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce35045-e7a4-4fa1-adc2-be08c55c6e32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "079d4f87-3eb7-4c44-b985-5db2f2c5bcda",
   "metadata": {},
   "source": [
    "# group analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c79fe63-8f62-4339-8a2f-6f31ef1b6753",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (PDM Environment)",
   "language": "python",
   "name": "pdm-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
