{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6293b6c4-b0b7-413c-91b4-f7e9d6666e84",
   "metadata": {},
   "source": [
    "Cleaned up coding pipeline for the discovery sample exploratory analyses. \n",
    "\n",
    "1_generate_second_model.ipynb loads in the first level contrast maps for all task/contrasts for each of the 5 discovery sample subjects. Then, it generates second level models (for each task/contrast, it creates 1 second level model for each encounter of the task). For example, since every subject has 5 sessions with a given task--although the specific session numbers are different--the subjects get combined for their first encounter of a given task, then the next model combines them for their second encounter of a given task, and so on. \n",
    "\n",
    "These second level models are then saved in the home directory: '/home/users/nklevak/network_data_updated/' under each specific task name folder (i.e. cuedTS, directedForgetting, flanker, goNogo, nBack, shapeMatching, spatialTS, stopSignal) and then the corresponding contrast folder. Filename format is: {taskName}_{contrastName}encounter{encounter_number}. The encounter numbers range from 1-5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd544612-5040-4670-9cf2-26a511acd474",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "import nilearn\n",
    "import json\n",
    "import datetime\n",
    "import warnings\n",
    "from nilearn import plotting\n",
    "from nilearn.glm.first_level import FirstLevelModel\n",
    "from nilearn.glm.second_level import SecondLevelModel\n",
    "from nilearn.glm import threshold_stats_img\n",
    "from nilearn.image import concat_imgs, mean_img, index_img\n",
    "from nilearn.reporting import make_glm_report\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21c03558-0705-432a-9132-249fa6647750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# where the updated second levels are saved (with the fixed tedana pipeline):\n",
    "OUTPUT_DIR = '/home/users/nklevak/network_data_second_lev/'\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# where the first level contrast maps are stored\n",
    "BASE_DIR = '/oak/stanford/groups/russpold/data/network_grant/discovery_BIDS_20250402/derivatives/'\n",
    "LEVEL = 'output_lev1_mni'\n",
    "\n",
    "# subjects in the discovery sample\n",
    "SUBJECTS = ['sub-s03', 'sub-s10', 'sub-s19', 'sub-s29', 'sub-s43']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c61d89ff-73c1-4e02-bcab-7c2c6450d457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# relevant task and contrast and session data\n",
    "TASKS = [\"nBack\",\"flanker\",\"directedForgetting\",\"goNogo\", \"shapeMatching\", \"stopSignal\", \"cuedTS\", \"spatialTS\"]\n",
    "CONTRASTS = {}\n",
    "CONTRASTS[\"nBack\"] = [\"twoBack-oneBack\", \"match-mismatch\",\"task-baseline\",\"response_time\"] # the nback contrasts\n",
    "CONTRASTS[\"flanker\"] = [\"incongruent-congruent\", \"task-baseline\", \"incongruent-congruent\",\"response_time\"]\n",
    "CONTRASTS[\"directedForgetting\"] = [\"neg-con\", \"task-baseline\",\"response_time\"]\n",
    "CONTRASTS[\"goNogo\"] = [\"nogo_success-go\", \"nogo_success\",\"task-baseline\",\"response_time\"] # go_rtModel check\n",
    "CONTRASTS[\"shapeMatching\"] = [\"DDD\", \"DDS\", \"DNN\", \"DSD\", \"main_vars\", \"SDD\", \"SNN\", \"SSS\", \"task-baseline\",\"response_time\"]\n",
    "CONTRASTS[\"stopSignal\"] = [\"go\", \"stop_failure-go\", \"stop_failure\", \"stop_failure-stop_success\", \"stop_success-go\", \"stop_success\", \"stop_success-stop_failure\", \"task-baseline\",\"response_time\"]\n",
    "CONTRASTS[\"cuedTS\"] = [\"cue_switch_cost\", \"task_switch_cost\", \"task_switch_cue_switch-task_stay_cue_stay\", \"task-baseline\",\"response_time\"]\n",
    "CONTRASTS[\"spatialTS\"] = [\"cue_switch_cost\", \"task_switch_cost\", \"task_switch_cue_switch-task_stay_cue_stay\", \"task-baseline\",\"response_time\"]\n",
    "SESSIONS = ['ses-01', 'ses-02', 'ses-03', 'ses-04', 'ses-05', 'ses-06', 'ses-07', 'ses-08', 'ses-09','ses-10']\n",
    "\n",
    "# number of encounters each subject has with a task\n",
    "max_num_encounters = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8bfccf34-dad4-4036-9dfa-6eb5c2b89666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions:\n",
    "\n",
    "def build_contrast_map_path(base_dir, level, subject, session, task, contrast_name):\n",
    "    \"\"\"Build the file path for a contrast map.\"\"\"\n",
    "    filename = f'{subject}_{session}_task-{task}_contrast-{contrast_name}_rtmodel-rt_centered_stat-effect-size.nii.gz'\n",
    "    return os.path.join(base_dir, level, subject, task, 'indiv_contrasts', filename)\n",
    "\n",
    "def is_valid_contrast_map(img_path):\n",
    "    \"\"\"Check if a contrast map has sufficient variance and no NaN values.\"\"\"\n",
    "    try:\n",
    "        img = nib.load(img_path)\n",
    "        data = img.get_fdata()\n",
    "        return np.std(data) > 1e-10 and not np.isnan(data).any()\n",
    "    except Exception as e:\n",
    "        print(f\"Error validating {img_path}: {e}\")\n",
    "        return False\n",
    "        \n",
    "def clean_z_map_data(z_map, task, contrast_name, encounter):\n",
    "    \"\"\"Clean z-map data by handling NaN and infinity values.\"\"\"\n",
    "    data = z_map.get_fdata()\n",
    "    if np.isnan(data).any() or np.isinf(data).any():\n",
    "        data = np.nan_to_num(data)\n",
    "        z_map = nib.Nifti1Image(data, z_map.affine, z_map.header)\n",
    "        print(f\"Warning: Fixed NaN/Inf values in {task}:{contrast_name}:encounter-{encounter+1}\")\n",
    "    return z_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86c74ae1-bd4e-40e4-b2f6-dc94ea8c1fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed nBack:twoBack-oneBack:encounter-1\n",
      "Completed nBack:twoBack-oneBack:encounter-2\n",
      "Completed nBack:twoBack-oneBack:encounter-3\n",
      "Completed nBack:twoBack-oneBack:encounter-4\n",
      "Completed nBack:twoBack-oneBack:encounter-5\n",
      "Completed nBack:match-mismatch:encounter-1\n",
      "Completed nBack:match-mismatch:encounter-2\n",
      "Completed nBack:match-mismatch:encounter-3\n",
      "Completed nBack:match-mismatch:encounter-4\n",
      "Completed nBack:match-mismatch:encounter-5\n",
      "Completed nBack:task-baseline:encounter-1\n",
      "Completed nBack:task-baseline:encounter-2\n",
      "Completed nBack:task-baseline:encounter-3\n",
      "Completed nBack:task-baseline:encounter-4\n",
      "Completed nBack:task-baseline:encounter-5\n",
      "Completed nBack:response_time:encounter-1\n",
      "Completed nBack:response_time:encounter-2\n",
      "Completed nBack:response_time:encounter-3\n",
      "Completed nBack:response_time:encounter-4\n",
      "Completed nBack:response_time:encounter-5\n",
      "Completed flanker:incongruent-congruent:encounter-1\n",
      "Completed flanker:incongruent-congruent:encounter-2\n",
      "Completed flanker:incongruent-congruent:encounter-3\n",
      "Completed flanker:incongruent-congruent:encounter-4\n",
      "Completed flanker:incongruent-congruent:encounter-5\n",
      "Completed flanker:task-baseline:encounter-1\n",
      "Completed flanker:task-baseline:encounter-2\n",
      "Completed flanker:task-baseline:encounter-3\n",
      "Completed flanker:task-baseline:encounter-4\n",
      "Completed flanker:task-baseline:encounter-5\n",
      "Completed flanker:incongruent-congruent:encounter-1\n",
      "Completed flanker:incongruent-congruent:encounter-2\n",
      "Completed flanker:incongruent-congruent:encounter-3\n",
      "Completed flanker:incongruent-congruent:encounter-4\n",
      "Completed flanker:incongruent-congruent:encounter-5\n",
      "Completed flanker:response_time:encounter-1\n",
      "Completed flanker:response_time:encounter-2\n",
      "Completed flanker:response_time:encounter-3\n",
      "Completed flanker:response_time:encounter-4\n",
      "Completed flanker:response_time:encounter-5\n",
      "Completed directedForgetting:neg-con:encounter-1\n",
      "Completed directedForgetting:neg-con:encounter-2\n",
      "Completed directedForgetting:neg-con:encounter-3\n",
      "Completed directedForgetting:neg-con:encounter-4\n",
      "Completed directedForgetting:neg-con:encounter-5\n",
      "Completed directedForgetting:task-baseline:encounter-1\n",
      "Completed directedForgetting:task-baseline:encounter-2\n",
      "Completed directedForgetting:task-baseline:encounter-3\n",
      "Completed directedForgetting:task-baseline:encounter-4\n",
      "Completed directedForgetting:task-baseline:encounter-5\n",
      "Completed directedForgetting:response_time:encounter-1\n",
      "Completed directedForgetting:response_time:encounter-2\n",
      "Completed directedForgetting:response_time:encounter-3\n",
      "Completed directedForgetting:response_time:encounter-4\n",
      "Completed directedForgetting:response_time:encounter-5\n",
      "Completed goNogo:nogo_success-go:encounter-1\n",
      "Completed goNogo:nogo_success-go:encounter-2\n",
      "Completed goNogo:nogo_success-go:encounter-3\n",
      "Completed goNogo:nogo_success-go:encounter-4\n",
      "Skipping goNogo:nogo_success-go:encounter-5 (insufficient data)\n",
      "Completed goNogo:nogo_success:encounter-1\n",
      "Completed goNogo:nogo_success:encounter-2\n",
      "Completed goNogo:nogo_success:encounter-3\n",
      "Completed goNogo:nogo_success:encounter-4\n",
      "Skipping goNogo:nogo_success:encounter-5 (insufficient data)\n",
      "Completed goNogo:task-baseline:encounter-1\n",
      "Completed goNogo:task-baseline:encounter-2\n",
      "Completed goNogo:task-baseline:encounter-3\n",
      "Completed goNogo:task-baseline:encounter-4\n",
      "Skipping goNogo:task-baseline:encounter-5 (insufficient data)\n",
      "Completed goNogo:response_time:encounter-1\n",
      "Completed goNogo:response_time:encounter-2\n",
      "Completed goNogo:response_time:encounter-3\n",
      "Completed goNogo:response_time:encounter-4\n",
      "Skipping goNogo:response_time:encounter-5 (insufficient data)\n",
      "Completed shapeMatching:DDD:encounter-1\n",
      "Completed shapeMatching:DDD:encounter-2\n",
      "Completed shapeMatching:DDD:encounter-3\n",
      "Completed shapeMatching:DDD:encounter-4\n",
      "Completed shapeMatching:DDD:encounter-5\n",
      "Completed shapeMatching:DDS:encounter-1\n",
      "Completed shapeMatching:DDS:encounter-2\n",
      "Completed shapeMatching:DDS:encounter-3\n",
      "Completed shapeMatching:DDS:encounter-4\n",
      "Completed shapeMatching:DDS:encounter-5\n",
      "Completed shapeMatching:DNN:encounter-1\n",
      "Completed shapeMatching:DNN:encounter-2\n",
      "Completed shapeMatching:DNN:encounter-3\n",
      "Completed shapeMatching:DNN:encounter-4\n",
      "Completed shapeMatching:DNN:encounter-5\n",
      "Completed shapeMatching:DSD:encounter-1\n",
      "Completed shapeMatching:DSD:encounter-2\n",
      "Completed shapeMatching:DSD:encounter-3\n",
      "Completed shapeMatching:DSD:encounter-4\n",
      "Completed shapeMatching:DSD:encounter-5\n",
      "Completed shapeMatching:main_vars:encounter-1\n",
      "Completed shapeMatching:main_vars:encounter-2\n",
      "Completed shapeMatching:main_vars:encounter-3\n",
      "Completed shapeMatching:main_vars:encounter-4\n",
      "Completed shapeMatching:main_vars:encounter-5\n",
      "Completed shapeMatching:SDD:encounter-1\n",
      "Completed shapeMatching:SDD:encounter-2\n",
      "Completed shapeMatching:SDD:encounter-3\n",
      "Completed shapeMatching:SDD:encounter-4\n",
      "Completed shapeMatching:SDD:encounter-5\n",
      "Completed shapeMatching:SNN:encounter-1\n",
      "Completed shapeMatching:SNN:encounter-2\n",
      "Completed shapeMatching:SNN:encounter-3\n",
      "Completed shapeMatching:SNN:encounter-4\n",
      "Completed shapeMatching:SNN:encounter-5\n",
      "Completed shapeMatching:SSS:encounter-1\n",
      "Completed shapeMatching:SSS:encounter-2\n",
      "Completed shapeMatching:SSS:encounter-3\n",
      "Completed shapeMatching:SSS:encounter-4\n",
      "Completed shapeMatching:SSS:encounter-5\n",
      "Completed shapeMatching:task-baseline:encounter-1\n",
      "Completed shapeMatching:task-baseline:encounter-2\n",
      "Completed shapeMatching:task-baseline:encounter-3\n",
      "Completed shapeMatching:task-baseline:encounter-4\n",
      "Completed shapeMatching:task-baseline:encounter-5\n",
      "Completed shapeMatching:response_time:encounter-1\n",
      "Completed shapeMatching:response_time:encounter-2\n",
      "Completed shapeMatching:response_time:encounter-3\n",
      "Completed shapeMatching:response_time:encounter-4\n",
      "Completed shapeMatching:response_time:encounter-5\n",
      "Completed stopSignal:go:encounter-1\n",
      "Completed stopSignal:go:encounter-2\n",
      "Completed stopSignal:go:encounter-3\n",
      "Completed stopSignal:go:encounter-4\n",
      "Completed stopSignal:go:encounter-5\n",
      "Completed stopSignal:stop_failure-go:encounter-1\n",
      "Completed stopSignal:stop_failure-go:encounter-2\n",
      "Completed stopSignal:stop_failure-go:encounter-3\n",
      "Completed stopSignal:stop_failure-go:encounter-4\n",
      "Completed stopSignal:stop_failure-go:encounter-5\n",
      "Completed stopSignal:stop_failure:encounter-1\n",
      "Completed stopSignal:stop_failure:encounter-2\n",
      "Completed stopSignal:stop_failure:encounter-3\n",
      "Completed stopSignal:stop_failure:encounter-4\n",
      "Completed stopSignal:stop_failure:encounter-5\n",
      "Completed stopSignal:stop_failure-stop_success:encounter-1\n",
      "Completed stopSignal:stop_failure-stop_success:encounter-2\n",
      "Completed stopSignal:stop_failure-stop_success:encounter-3\n",
      "Completed stopSignal:stop_failure-stop_success:encounter-4\n",
      "Completed stopSignal:stop_failure-stop_success:encounter-5\n",
      "Completed stopSignal:stop_success-go:encounter-1\n",
      "Completed stopSignal:stop_success-go:encounter-2\n",
      "Completed stopSignal:stop_success-go:encounter-3\n",
      "Completed stopSignal:stop_success-go:encounter-4\n",
      "Completed stopSignal:stop_success-go:encounter-5\n",
      "Completed stopSignal:stop_success:encounter-1\n",
      "Completed stopSignal:stop_success:encounter-2\n",
      "Completed stopSignal:stop_success:encounter-3\n",
      "Completed stopSignal:stop_success:encounter-4\n",
      "Completed stopSignal:stop_success:encounter-5\n",
      "Completed stopSignal:stop_success-stop_failure:encounter-1\n",
      "Completed stopSignal:stop_success-stop_failure:encounter-2\n",
      "Completed stopSignal:stop_success-stop_failure:encounter-3\n",
      "Completed stopSignal:stop_success-stop_failure:encounter-4\n",
      "Completed stopSignal:stop_success-stop_failure:encounter-5\n",
      "Completed stopSignal:task-baseline:encounter-1\n",
      "Completed stopSignal:task-baseline:encounter-2\n",
      "Completed stopSignal:task-baseline:encounter-3\n",
      "Completed stopSignal:task-baseline:encounter-4\n",
      "Completed stopSignal:task-baseline:encounter-5\n",
      "Completed stopSignal:response_time:encounter-1\n",
      "Completed stopSignal:response_time:encounter-2\n",
      "Completed stopSignal:response_time:encounter-3\n",
      "Completed stopSignal:response_time:encounter-4\n",
      "Completed stopSignal:response_time:encounter-5\n",
      "Completed cuedTS:cue_switch_cost:encounter-1\n",
      "Completed cuedTS:cue_switch_cost:encounter-2\n",
      "Completed cuedTS:cue_switch_cost:encounter-3\n",
      "Completed cuedTS:cue_switch_cost:encounter-4\n",
      "Completed cuedTS:cue_switch_cost:encounter-5\n",
      "Completed cuedTS:task_switch_cost:encounter-1\n",
      "Completed cuedTS:task_switch_cost:encounter-2\n",
      "Completed cuedTS:task_switch_cost:encounter-3\n",
      "Completed cuedTS:task_switch_cost:encounter-4\n",
      "Completed cuedTS:task_switch_cost:encounter-5\n",
      "Completed cuedTS:task_switch_cue_switch-task_stay_cue_stay:encounter-1\n",
      "Completed cuedTS:task_switch_cue_switch-task_stay_cue_stay:encounter-2\n",
      "Completed cuedTS:task_switch_cue_switch-task_stay_cue_stay:encounter-3\n",
      "Completed cuedTS:task_switch_cue_switch-task_stay_cue_stay:encounter-4\n",
      "Completed cuedTS:task_switch_cue_switch-task_stay_cue_stay:encounter-5\n",
      "Completed cuedTS:task-baseline:encounter-1\n",
      "Completed cuedTS:task-baseline:encounter-2\n",
      "Completed cuedTS:task-baseline:encounter-3\n",
      "Completed cuedTS:task-baseline:encounter-4\n",
      "Completed cuedTS:task-baseline:encounter-5\n",
      "Completed cuedTS:response_time:encounter-1\n",
      "Completed cuedTS:response_time:encounter-2\n",
      "Completed cuedTS:response_time:encounter-3\n",
      "Completed cuedTS:response_time:encounter-4\n",
      "Completed cuedTS:response_time:encounter-5\n",
      "Completed spatialTS:cue_switch_cost:encounter-1\n",
      "Completed spatialTS:cue_switch_cost:encounter-2\n",
      "Completed spatialTS:cue_switch_cost:encounter-3\n",
      "Completed spatialTS:cue_switch_cost:encounter-4\n",
      "Completed spatialTS:cue_switch_cost:encounter-5\n",
      "Completed spatialTS:task_switch_cost:encounter-1\n",
      "Completed spatialTS:task_switch_cost:encounter-2\n",
      "Completed spatialTS:task_switch_cost:encounter-3\n",
      "Completed spatialTS:task_switch_cost:encounter-4\n",
      "Completed spatialTS:task_switch_cost:encounter-5\n",
      "Completed spatialTS:task_switch_cue_switch-task_stay_cue_stay:encounter-1\n",
      "Completed spatialTS:task_switch_cue_switch-task_stay_cue_stay:encounter-2\n",
      "Completed spatialTS:task_switch_cue_switch-task_stay_cue_stay:encounter-3\n",
      "Completed spatialTS:task_switch_cue_switch-task_stay_cue_stay:encounter-4\n",
      "Completed spatialTS:task_switch_cue_switch-task_stay_cue_stay:encounter-5\n",
      "Completed spatialTS:task-baseline:encounter-1\n",
      "Completed spatialTS:task-baseline:encounter-2\n",
      "Completed spatialTS:task-baseline:encounter-3\n",
      "Completed spatialTS:task-baseline:encounter-4\n",
      "Completed spatialTS:task-baseline:encounter-5\n",
      "Completed spatialTS:response_time:encounter-1\n",
      "Completed spatialTS:response_time:encounter-2\n",
      "Completed spatialTS:response_time:encounter-3\n",
      "Completed spatialTS:response_time:encounter-4\n",
      "Completed spatialTS:response_time:encounter-5\n"
     ]
    }
   ],
   "source": [
    "# Load first level contrast map filepaths for all tasks and contrasts\n",
    "all_contrast_maps = defaultdict(lambda: defaultdict(lambda: defaultdict(list)))\n",
    "encounter_maps = defaultdict(lambda: defaultdict(lambda: defaultdict(dict)))\n",
    "\n",
    "for task in TASKS:\n",
    "    for contrast_name in CONTRASTS[task]:\n",
    "        for subject in SUBJECTS:\n",
    "            overall_encounter_count = 0\n",
    "            \n",
    "            for session in SESSIONS:\n",
    "                contrast_map_path = build_contrast_map_path(BASE_DIR, LEVEL, subject, session, task, contrast_name)\n",
    "                \n",
    "                if os.path.exists(contrast_map_path):\n",
    "                    all_contrast_maps[task][contrast_name][subject].append(contrast_map_path)\n",
    "                    encounter_maps[task][contrast_name][subject][overall_encounter_count] = contrast_map_path\n",
    "                    overall_encounter_count += 1\n",
    "\n",
    "# Sort contrast maps by encounter number (grouping all subjects together)\n",
    "session_contrast_maps = defaultdict(lambda: defaultdict(lambda: defaultdict(list)))\n",
    "session_design_rows = defaultdict(lambda: defaultdict(lambda: defaultdict(list)))\n",
    "\n",
    "for task in TASKS:\n",
    "    for contrast_name in CONTRASTS[task]:\n",
    "        for encounter in range(max_num_encounters):\n",
    "            for subject in SUBJECTS:\n",
    "                subject_numeric = np.float64(float(subject[5:]))\n",
    "                \n",
    "                if (subject in encounter_maps[task][contrast_name] and \n",
    "                    encounter in encounter_maps[task][contrast_name][subject]):\n",
    "                    \n",
    "                    map_path = encounter_maps[task][contrast_name][subject][encounter]\n",
    "                    session_contrast_maps[task][contrast_name][encounter].append(map_path)\n",
    "                    session_design_rows[task][contrast_name][encounter].append({\n",
    "                        'subject': subject_numeric,\n",
    "                        # Add any subject-specific covariates here\n",
    "                        # 'performance': performance[subject][session]\n",
    "                    })\n",
    "\n",
    "# Create all second-level model z-maps (1 per encounter)\n",
    "secondLevelZmaps = defaultdict(lambda: defaultdict(dict))\n",
    "\n",
    "for task in TASKS:\n",
    "    for contrast_name in CONTRASTS[task]:\n",
    "        for encounter in range(5):  # You can make this configurable\n",
    "            maps = session_contrast_maps[task][contrast_name][encounter]\n",
    "            rows = session_design_rows[task][contrast_name][encounter]\n",
    "            \n",
    "            # Skip if fewer than minimum required subjects\n",
    "            if len(maps) < 4:\n",
    "                print(f\"Skipping {task}:{contrast_name}:encounter-{encounter+1} (insufficient data)\")\n",
    "                secondLevelZmaps[task][contrast_name][encounter] = None\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                # Create design matrix\n",
    "                dm = pd.DataFrame(rows)\n",
    "                dm['intercept'] = 1  # Add intercept column (group effect)\n",
    "                \n",
    "                # Check for design matrix issues\n",
    "                if dm.shape[0] <= dm.shape[1]:\n",
    "                    print(f\"Warning: More regressors than subjects for {task}:{contrast_name}:encounter-{encounter+1}\")\n",
    "                \n",
    "                # Filter out invalid maps\n",
    "                valid_maps = []\n",
    "                valid_rows = []\n",
    "                \n",
    "                for i, map_path in enumerate(maps):\n",
    "                    if is_valid_contrast_map(map_path):\n",
    "                        valid_maps.append(nib.load(map_path))\n",
    "                        valid_rows.append(dm.iloc[i])\n",
    "                \n",
    "                if len(valid_maps) < 4:\n",
    "                    print(f\"Skipping {task}:{contrast_name}:encounter-{encounter+1} (insufficient valid maps)\")\n",
    "                    secondLevelZmaps[task][contrast_name][encounter] = None\n",
    "                    continue\n",
    "                \n",
    "                # Recreate design matrix with only valid subjects\n",
    "                valid_dm = pd.DataFrame(valid_rows).reset_index(drop=True)\n",
    "                \n",
    "                # Create and fit second-level model\n",
    "                second_level_model = SecondLevelModel(smoothing_fwhm=8.0)\n",
    "                \n",
    "                with warnings.catch_warnings():\n",
    "                    warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "                    second_level_model.fit(valid_maps, design_matrix=valid_dm)\n",
    "                    z_map = second_level_model.compute_contrast(\n",
    "                        second_level_contrast='intercept',\n",
    "                        output_type='z_score'\n",
    "                    )\n",
    "                \n",
    "                # Clean z-map data\n",
    "                z_map = clean_z_map_data(z_map, task, contrast_name, encounter)\n",
    "                \n",
    "                secondLevelZmaps[task][contrast_name][encounter] = z_map\n",
    "                print(f\"Completed {task}:{contrast_name}:encounter-{encounter+1}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {task}:{contrast_name}:encounter-{encounter+1}: {e}\")\n",
    "                secondLevelZmaps[task][contrast_name][encounter] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64d2a672-36e6-4774-bafa-16bd6f2c86c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error saving goNogo:nogo_success-go:encounter-5: 'NoneType' object has no attribute 'to_filename'\n",
      "Error saving goNogo:nogo_success:encounter-5: 'NoneType' object has no attribute 'to_filename'\n",
      "Error saving goNogo:task-baseline:encounter-5: 'NoneType' object has no attribute 'to_filename'\n",
      "Error saving goNogo:response_time:encounter-5: 'NoneType' object has no attribute 'to_filename'\n",
      "Saved 211 zmaps with metadata. Skipped 4 maps.\n"
     ]
    }
   ],
   "source": [
    "# save all of the second level zmaps to the output directory\n",
    "# Create a function to save zmaps with metadata\n",
    "def save_zmaps_with_metadata(zmaps_dict, output_dir=OUTPUT_DIR):\n",
    "    \"\"\"\n",
    "    Save zmaps with corresponding metadata json files in BIDS-like format.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    zmaps_dict : dict\n",
    "        Nested dictionary of zmaps organized by task, contrast, and encounter.\n",
    "    output_dir : str\n",
    "        Directory where files will be saved.\n",
    "    \"\"\"\n",
    "    # Get current date for metadata\n",
    "    current_date = datetime.datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "    num_saved = 0\n",
    "    num_skipped = 0\n",
    "    for task in zmaps_dict:\n",
    "        # Create task directory\n",
    "        task_dir = os.path.join(output_dir, task)\n",
    "        os.makedirs(task_dir, exist_ok=True)\n",
    "        \n",
    "        for contrast_name in zmaps_dict[task]:\n",
    "            # Create contrast directory\n",
    "            contrast_dir = os.path.join(task_dir, contrast_name)\n",
    "            os.makedirs(contrast_dir, exist_ok=True)\n",
    "            \n",
    "            for encounter_idx, zmap in zmaps_dict[task][contrast_name].items():\n",
    "                # Define base filename\n",
    "                base_filename = f\"{task}_{contrast_name}encounter{encounter_idx+1}\"\n",
    "                full_path = os.path.join(contrast_dir, base_filename)\n",
    "\n",
    "                try:\n",
    "                    # Save NIfTI file\n",
    "                    zmap.to_filename(f\"{full_path}.nii.gz\")\n",
    "                    num_saved += 1\n",
    "                    \n",
    "                    # Create and save metadata\n",
    "                    metadata = {\n",
    "                        \"TaskName\": task,\n",
    "                        \"ContrastName\": contrast_name,\n",
    "                        \"EncounterNumber\": encounter_idx + 1,\n",
    "                        \"DataType\": \"z_statistic_map\",\n",
    "                        \"AnalysisDate\": current_date,\n",
    "                        \"SmoothinFWHM\": 8.0,  # From model\n",
    "                        \"ContrastType\": \"intercept\",  # From contrast\n",
    "                        \"OutputType\": \"z_score\"  # From output type\n",
    "                    }\n",
    "    \n",
    "                    # Save metadata to JSON file\n",
    "                    with open(f\"{full_path}.json\", 'w') as f:\n",
    "                        json.dump(metadata, f, indent=4)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error saving {task}:{contrast_name}:encounter-{encounter_idx+1}: {e}\")\n",
    "                    num_skipped += 1\n",
    "                \n",
    "    print(f\"Saved {num_saved} zmaps with metadata. Skipped {num_skipped} maps.\")\n",
    "    \n",
    "# save updated zmaps to folder\n",
    "save_zmaps_with_metadata(secondLevelZmaps)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (PDM Environment)",
   "language": "python",
   "name": "pdm-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
