{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ea39f25-67ad-4d04-a8e7-99ffa09e271c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaned up and generalized version of \"t_identify_regions_activation.ipynb\"\n",
    "# for each task + main condition, looks at main ROIs suggested by neurosynth \n",
    "# and how within and between subj spatial correlations change across encounters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00925bc2-bfbb-4cba-b523-7d149c86b36e",
   "metadata": {},
   "source": [
    "# imports and general helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "750f404c-34e6-4a72-964b-5ecbd60768c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "import nilearn\n",
    "import json\n",
    "import datetime\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import gc\n",
    "import psutil\n",
    "import math\n",
    "import scipy.stats as stats\n",
    "from matplotlib.patches import Patch\n",
    "from nilearn import plotting\n",
    "from nilearn.glm.first_level import FirstLevelModel\n",
    "from nilearn.glm.second_level import SecondLevelModel\n",
    "from nilearn.glm import threshold_stats_img\n",
    "from nilearn.image import concat_imgs, mean_img, index_img\n",
    "from nilearn.reporting import make_glm_report\n",
    "from nilearn import masking, image\n",
    "from nilearn import datasets\n",
    "from scipy.stats import pearsonr\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb5b5f5f-61eb-40fc-a50d-21482875be0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general helper functions:\n",
    "def build_contrast_map_path(base_dir, level, subject, session, task, contrast_name):\n",
    "    \"\"\"Build the file path for a contrast map.\"\"\"\n",
    "    filename = f'{subject}_{session}_task-{task}_contrast-{contrast_name}_rtmodel-rt_centered_stat-effect-size.nii.gz'\n",
    "    \n",
    "    # NOTE: as of 7/6/25 for sub 10 in flanker the format is different: sub-s10_ses-01_run-1_task-flanker_contrast-incongruent-congruent_rtmodel-rt_centered_stat-effect-size.nii.gz\n",
    "    if (subject == 'sub-s10' and task == 'flanker'):\n",
    "        filename = f'{subject}_{session}_run-1_task-{task}_contrast-{contrast_name}_rtmodel-rt_centered_stat-effect-size.nii.gz'\n",
    "        \n",
    "    return os.path.join(base_dir, level, subject, task, 'indiv_contrasts', filename)\n",
    "\n",
    "def is_valid_contrast_map(img_path):\n",
    "    \"\"\"Check if a contrast map has sufficient variance and no NaN values.\"\"\"\n",
    "    try:\n",
    "        img = nib.load(img_path)\n",
    "        data = img.get_fdata()\n",
    "        return np.std(data) > 1e-10 and not np.isnan(data).any()\n",
    "    except Exception as e:\n",
    "        print(f\"Error validating {img_path}: {e}\")\n",
    "        return False\n",
    "        \n",
    "def clean_z_map_data(z_map, task, contrast_name, encounter):\n",
    "    \"\"\"Clean z-map data by handling NaN and infinity values.\"\"\"\n",
    "    data = z_map.get_fdata()\n",
    "    if np.isnan(data).any() or np.isinf(data).any():\n",
    "        data = np.nan_to_num(data)\n",
    "        z_map = nib.Nifti1Image(data, z_map.affine, z_map.header)\n",
    "        print(f\"Warning: Fixed NaN/Inf values in {task}:{contrast_name}:encounter-{encounter+1}\")\n",
    "    return z_map\n",
    "\n",
    "def save_rsm(rsm_results, filename):\n",
    "    \"\"\"\n",
    "    Simple save function\n",
    "    \n",
    "    Parameters:\n",
    "        rsm_results: RSM results dictionary\n",
    "        filename: filename to save (will add .pkl automatically)\n",
    "    \"\"\"\n",
    "    if not filename.endswith('.pkl'):\n",
    "        filename += '.pkl'\n",
    "    \n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(rsm_results, f)\n",
    "    \n",
    "    file_size = os.path.getsize(filename) / (1024 * 1024)\n",
    "    print(f\"Saved to {filename} ({file_size:.1f} MB)\")\n",
    "\n",
    "def load_rsm(filename):\n",
    "    \"\"\"\n",
    "    Simple load function\n",
    "    \n",
    "    Parameters:\n",
    "        filename: filename to load\n",
    "    \n",
    "    Returns:\n",
    "        rsm_results: Loaded RSM dictionary\n",
    "    \"\"\"\n",
    "    if not filename.endswith('.pkl'):\n",
    "        filename += '.pkl'\n",
    "    \n",
    "    with open(filename, 'rb') as f:\n",
    "        rsm_results = pickle.load(f)\n",
    "    \n",
    "    print(f\"Loaded from {filename}\")\n",
    "    return rsm_results\n",
    "\n",
    "def cleanup_memory():\n",
    "    \"\"\"\n",
    "    Clean up memory between batches\n",
    "    \"\"\"\n",
    "    # Force garbage collection\n",
    "    gc.collect()\n",
    "    \n",
    "    # Get memory info\n",
    "    memory = psutil.virtual_memory()\n",
    "    print(f\"Memory after cleanup: {memory.percent:.1f}% used ({memory.available/(1024**3):.1f}GB available)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463614e4-6c0e-4a26-bb23-9865c6eec208",
   "metadata": {},
   "source": [
    "# constants, filenames, and roi labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca95c3a5-4274-4b47-b306-3f51699ca62f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'defaultdict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m CONTRASTS[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspatialTS\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcue_switch_cost\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtask_switch_cost\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtask_switch_cue_switch-task_stay_cue_stay\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtask-baseline\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_time\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# main conditions and contrasts that we're interested in looking at\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m requested_task_contrasts \u001b[38;5;241m=\u001b[39m \u001b[43mdefaultdict\u001b[49m(\u001b[38;5;28;01mlambda\u001b[39;00m: defaultdict(\u001b[38;5;28mlist\u001b[39m))\n\u001b[1;32m     15\u001b[0m requested_task_contrasts[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnBack\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtwoBack-oneBack\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtask-baseline\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     16\u001b[0m requested_task_contrasts[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mflanker\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincongruent-congruent\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtask-baseline\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'defaultdict' is not defined"
     ]
    }
   ],
   "source": [
    "# all tasks and contrasts\n",
    "TASKS = [\"nBack\",\"flanker\",\"directedForgetting\",\"goNogo\", \"shapeMatching\", \"stopSignal\", \"cuedTS\", \"spatialTS\"]\n",
    "CONTRASTS = {}\n",
    "CONTRASTS[\"nBack\"] = [\"twoBack-oneBack\", \"match-mismatch\",\"task-baseline\",\"response_time\"] # the nback contrasts\n",
    "CONTRASTS[\"flanker\"] = [\"incongruent-congruent\", \"task-baseline\", \"incongruent-congruent\",\"response_time\"]\n",
    "CONTRASTS[\"directedForgetting\"] = [\"neg-con\", \"task-baseline\",\"response_time\"]\n",
    "CONTRASTS[\"goNogo\"] = [\"nogo_success-go\", \"nogo_success\",\"task-baseline\",\"response_time\"] # go_rtModel check\n",
    "CONTRASTS[\"shapeMatching\"] = [\"DDD\", \"DDS\", \"DNN\", \"DSD\", \"main_vars\", \"SDD\", \"SNN\", \"SSS\", \"task-baseline\",\"response_time\"]\n",
    "CONTRASTS[\"stopSignal\"] = [\"go\", \"stop_failure-go\", \"stop_failure\", \"stop_failure-stop_success\", \"stop_success-go\", \"stop_success\", \"stop_success-stop_failure\", \"task-baseline\",\"response_time\"]\n",
    "CONTRASTS[\"cuedTS\"] = [\"cue_switch_cost\", \"task_switch_cost\", \"task_switch_cue_switch-task_stay_cue_stay\", \"task-baseline\",\"response_time\"]\n",
    "CONTRASTS[\"spatialTS\"] = [\"cue_switch_cost\", \"task_switch_cost\", \"task_switch_cue_switch-task_stay_cue_stay\", \"task-baseline\",\"response_time\"]\n",
    "\n",
    "# main conditions and contrasts that we're interested in looking at\n",
    "requested_task_contrasts = defaultdict(lambda: defaultdict(list))\n",
    "requested_task_contrasts['nBack'] = [\"twoBack-oneBack\", 'task-baseline']\n",
    "requested_task_contrasts['flanker'] = [\"incongruent-congruent\",'task-baseline']\n",
    "requested_task_contrasts['directedForgetting'] = [\"neg-con\",'task-baseline']\n",
    "requested_task_contrasts['goNogo'] = [\"nogo_success-go\",'task-baseline']\n",
    "requested_task_contrasts['shapeMatching'] = [\"main_vars\",'task-baseline']\n",
    "requested_task_contrasts['stopSignal'] = [\"stop_failure-go\",'task-baseline']\n",
    "requested_task_contrasts['cuedTS'] = [\"task_switch_cost\",'task-baseline']\n",
    "requested_task_contrasts['spatialTS'] = [\"task_switch_cost\",'task-baseline']\n",
    "\n",
    "# main ROI short-names and the corresponding filenames / loaded maps\n",
    "requested_ROI_files = defaultdict(lambda: defaultdict(lambda: defaultdict(list)))\n",
    "requested_ROI_files[\"response-inhibition\"] = {'filename': './neurosynth_rois/response_inhibition_association-test_z_FDR_0.01.nii'}\n",
    "requested_ROI_files['inhibitory-control'] = {'filename': './neurosynth_rois/inhibitory_control_association-test_z_FDR_0.01.nii'}\n",
    "requested_ROI_files['working-memory'] = {'filename': './neurosynth_rois/working_memory_association-test_z_FDR_0.01.nii'}\n",
    "requested_ROI_files['attentional-control'] = {'filename': './neurosynth_rois/attentional_control_association-test_z_FDR_0.01.nii'}\n",
    "requested_ROI_files['dlpfc'] = {'filename': './neurosynth_rois/dlpfc_association-test_z_FDR_0.01.nii'}\n",
    "requested_ROI_files['ips'] = {'filename': './neurosynth_rois/ips_association-test_z_FDR_0.01.nii'}\n",
    "requested_ROI_files['acc'] = {'filename': './neurosynth_rois/acc_association-test_z_FDR_0.01.nii'}\n",
    "requested_ROI_files['rifg'] = {} # loaded later from response inhibition\n",
    "requested_ROI_files['pre-sma'] = {} # loaded later from response inhibition\n",
    "\n",
    "# main ROIs per task that we're interested in looking at\n",
    "requested_task_rois = defaultdict(lambda: defaultdict(list))\n",
    "requested_task_rois['nBack'] = [\"working-memory\", \"attentional-control\", \"dlpfc\",\"ips\"]\n",
    "requested_task_rois['flanker'] = [\"inhibitory-control\", \"dlpfc\",\"acc\",\"ips\"]\n",
    "requested_task_rois['directedForgetting'] = [\"response-inhibition\",\"working-memory\",  \"attentional-control\", \"dlpfc\",\"acc\"]\n",
    "requested_task_rois['goNogo'] = [\"response-inhibition\", \"rifg\", \"pre-sma\"]\n",
    "requested_task_rois['shapeMatching'] = [\"working-memory\",\"attentional-control\",\"inhibitory-control\", \"dlpfc\",\"ips\",\"acc\"]\n",
    "requested_task_rois['stopSignal'] = [\"response-inhibition\", \"attentional-control\",\"rifg\", \"pre-sma\"]\n",
    "requested_task_rois['cuedTS'] = [\"inhibitory-control\",\"working-memory\", \"attentional-control\", \"dlpfc\",\"ips\"]\n",
    "requested_task_rois['spatialTS'] = [\"attentional-control\", \"working-memory\", \"inhibitory-control\", \"dlpfc\",\"ips\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418535ea-8134-42b2-a27d-cf8eaeb56069",
   "metadata": {},
   "source": [
    "# load subject files per session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52bb693d-49ad-4450-8041-4a1cbbb48d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load files per subject per session\n",
    "\n",
    "# where the first level contrast maps are stored\n",
    "BASE_DIR = '/oak/stanford/groups/russpold/data/network_grant/discovery_BIDS_20250402/derivatives/'\n",
    "LEVEL = 'output_lev1_mni'\n",
    "# subjects in the discovery sample\n",
    "SUBJECTS = ['sub-s03', 'sub-s10', 'sub-s19', 'sub-s29', 'sub-s43']\n",
    "SESSIONS = ['ses-01', 'ses-02', 'ses-03', 'ses-04', 'ses-05', 'ses-06', 'ses-07', 'ses-08', 'ses-09','ses-10']\n",
    "\n",
    "# number of encounters each subject has with a task\n",
    "max_num_encounters = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5d7da82-62a3-4060-977c-d9e69c4bfedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# arrange each subjects maps by which encounter num it is\n",
    "all_contrast_maps = defaultdict(lambda: defaultdict(lambda: defaultdict(list)))\n",
    "encounter_maps = defaultdict(lambda: defaultdict(lambda: defaultdict(dict)))\n",
    "\n",
    "for task in TASKS:\n",
    "    for contrast_name in CONTRASTS[task]:\n",
    "        for subject in SUBJECTS:\n",
    "            overall_encounter_count = 0\n",
    "            \n",
    "            for session in SESSIONS:\n",
    "                contrast_map_path = build_contrast_map_path(BASE_DIR, LEVEL, subject, session, task, contrast_name)\n",
    "                \n",
    "                if os.path.exists(contrast_map_path):\n",
    "                    all_contrast_maps[task][contrast_name][subject].append(contrast_map_path)\n",
    "                    encounter_maps[task][contrast_name][subject][overall_encounter_count] = contrast_map_path\n",
    "                    overall_encounter_count += 1\n",
    "\n",
    "first_level_session_maps = all_contrast_maps\n",
    "first_level_encounter_maps = encounter_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df1cb224-d7aa-48f8-b18b-10bcbf337842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# relevant loading functions taken from 3_create_RSMs_first_level\n",
    "# function to gather maps of a certain task/contrast from first_level_encounter_maps\n",
    "def gather_tc_maps(req_tasks,req_contrasts,all_maps=first_level_encounter_maps,req_encounters=[0,1,2,3,4], req_subjects = SUBJECTS):\n",
    "    '''\n",
    "    Get a list of loaded niftis for specific task/contrast/encounter combinations of first level maps \n",
    "    \n",
    "    Parameters\n",
    "        req_tasks: list of tasks as strings (all tasks have to be from the TASKS dict)\n",
    "        req_contrasts: list of contrasts as strings (all tasks have to be from the CONTRASTS dict)\n",
    "        all_maps: [task][contrast_name][subject][overall_encounter_count] -> one map each (here it is in a filepath format)\n",
    "        req_encounters: list of encounter numbers that are requested (default is all 5)\n",
    "        req_subjects: list of subject id strings that are requested (default is all in SUBJECTS)\n",
    "    Return\n",
    "        specified_maps: list of loaded nifti files that fit the requested task, contrast, and encounter (this returns this for all subjects)\n",
    "        specified_descriptors: list of descriptions of each file (i.e. titles)\n",
    "        data_title: informative title for the RSM that will later be created\n",
    "    \n",
    "    '''\n",
    "    specified_maps = []\n",
    "    specified_descriptors = []\n",
    "    max_num_encounters = 5\n",
    "\n",
    "    if (len(req_tasks) == 0) or (len(req_contrasts) == 0):\n",
    "        return [], [], ''\n",
    "\n",
    "    for task in req_tasks:\n",
    "        if task not in TASKS:\n",
    "            print(f\"task {task} not in task masterlist\")\n",
    "            continue\n",
    "    \n",
    "        for contrast in req_contrasts:\n",
    "            if contrast not in CONTRASTS[task]: # make sure this contrast exists in the given task\n",
    "                print(f\"skipped for contrast {contrast} and task {task}\")\n",
    "                continue\n",
    "                \n",
    "            for subject in req_subjects:\n",
    "                if subject not in SUBJECTS:\n",
    "                    print(f\"subject: {subject} is not in this dataset, so skipped\")\n",
    "                    continue\n",
    "                    \n",
    "                for encounter in req_encounters:\n",
    "                    if encounter < 0 or encounter >= max_num_encounters:\n",
    "                        continue\n",
    "\n",
    "                    descriptor_name = f\"{subject}:encounter-0{encounter + 1}\"\n",
    "                            \n",
    "                    if task in all_maps.keys():\n",
    "                        if contrast in all_maps[task].keys():\n",
    "                            if subject in all_maps[task][contrast].keys():\n",
    "                                if encounter in all_maps[task][contrast][subject].keys():\n",
    "\n",
    "                                    map_data = all_maps[task][contrast][subject][encounter]\n",
    "                                    \n",
    "                                    # Check if file is already loaded\n",
    "                                    if isinstance(map_data, str):\n",
    "                                        # map_data is a file path, need to load it\n",
    "                                        try:\n",
    "                                            if os.path.exists(map_data):\n",
    "                                                loaded_map = nib.load(map_data)\n",
    "                                                specified_maps.append(loaded_map)\n",
    "                                                specified_descriptors.append(descriptor_name)\n",
    "                                            else:\n",
    "                                                print(f\"File not found: {map_data}\")\n",
    "                                                failed_loads.append((descriptor_name, \"File not found\"))\n",
    "                                        except Exception as e:\n",
    "                                            print(f\"Error loading {map_data}: {str(e)}\")\n",
    "                                    else:\n",
    "                                        print(f\"Unexpected data type for {descriptor_name}: {type(map_data)}\")\n",
    "                                        \n",
    "                                else:\n",
    "                                    print(f\"{task}|{contrast}|{subject}: {encounter}\")\n",
    "                                    continue\n",
    "                            else:\n",
    "                                print(f\"{task}|{contrast} subject {subject}\")\n",
    "                                continue\n",
    "                        else:\n",
    "                            print(f\"{task}:{contrast}\")\n",
    "                            continue\n",
    "                    else:\n",
    "                        print(f\"{task}\")\n",
    "                        continue\n",
    "    # create RSM title\n",
    "    data_title = ''\n",
    "    if (len(req_tasks) == 1):\n",
    "        data_title += f'Task:{req_tasks[0]}|'\n",
    "    else:  # more than 1 task\n",
    "        data_title += 'Task:'\n",
    "        for i, task in enumerate(req_tasks):\n",
    "            if (i != len(req_tasks) - 1):\n",
    "                data_title += f\"{task},\"\n",
    "            else:\n",
    "                data_title += f\"{task}\"\n",
    "        data_title += '|'\n",
    "\n",
    "    if (len(req_contrasts) == 1):\n",
    "        data_title += f'Contrast:{req_contrasts[0]}'\n",
    "    else:\n",
    "        data_title += 'Contrast:'\n",
    "        for i, contrast in enumerate(req_contrasts):\n",
    "            if (i != (len(req_contrasts) - 1)):\n",
    "                data_title += f\"{contrast},\"\n",
    "            else:\n",
    "                data_title += f\"{contrast}\"\n",
    "    \n",
    "    return specified_maps, specified_descriptors, data_title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51212247-e210-4e19-b1dd-07e7c9683d4b",
   "metadata": {},
   "source": [
    "# general loading and plotting functions that can apply across all tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c612764-8419-480c-9d05-1ca2c6a8d8ab",
   "metadata": {},
   "source": [
    "# analyzing per task/contrast/relevant ROI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24820334-a98c-4b80-95b2-a905784b9391",
   "metadata": {},
   "source": [
    "## go no go"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b7300f-d6c8-410d-ac87-77ad1c1f0dba",
   "metadata": {},
   "source": [
    "## flanker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9462ac33-c9cc-4d04-a196-da3d9cd87709",
   "metadata": {},
   "source": [
    "## directed forgetting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6affabb5-36e6-47bc-bd86-6d4d1fc75f7c",
   "metadata": {},
   "source": [
    "## nBack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb4f09f-ed41-4416-b228-cfeb21b9b0da",
   "metadata": {},
   "source": [
    "## shape matching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ed9aeb-035d-4fe8-924d-1ae4e5d676ee",
   "metadata": {},
   "source": [
    "## stop signal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12f159f-a4d8-4dd3-8534-416561a11526",
   "metadata": {},
   "source": [
    "## cued task switching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1fffa4-cf3f-4846-80e7-b730d4965a59",
   "metadata": {},
   "source": [
    "## spatial task switching"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (PDM Environment)",
   "language": "python",
   "name": "pdm-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
